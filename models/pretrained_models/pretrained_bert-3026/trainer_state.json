{
  "best_global_step": 2750,
  "best_metric": 0.004397871904075146,
  "best_model_checkpoint": null,
  "epoch": 17.0,
  "eval_steps": 50,
  "global_step": 3026,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.056417489421720736,
      "grad_norm": 1.1103119850158691,
      "learning_rate": 4.9915730337078655e-05,
      "loss": 0.1841,
      "step": 10
    },
    {
      "epoch": 0.11283497884344147,
      "grad_norm": 0.45836448669433594,
      "learning_rate": 4.982209737827715e-05,
      "loss": 0.0745,
      "step": 20
    },
    {
      "epoch": 0.1692524682651622,
      "grad_norm": 0.24278227984905243,
      "learning_rate": 4.972846441947566e-05,
      "loss": 0.044,
      "step": 30
    },
    {
      "epoch": 0.22566995768688294,
      "grad_norm": 0.1389167755842209,
      "learning_rate": 4.9634831460674155e-05,
      "loss": 0.0332,
      "step": 40
    },
    {
      "epoch": 0.2820874471086037,
      "grad_norm": 0.11057119816541672,
      "learning_rate": 4.954119850187266e-05,
      "loss": 0.0295,
      "step": 50
    },
    {
      "epoch": 0.2820874471086037,
      "eval_loss": 0.02102215588092804,
      "eval_runtime": 23.0119,
      "eval_samples_per_second": 1971.978,
      "eval_steps_per_second": 3.868,
      "step": 50
    },
    {
      "epoch": 0.3385049365303244,
      "grad_norm": 0.09288907796144485,
      "learning_rate": 4.9447565543071164e-05,
      "loss": 0.0276,
      "step": 60
    },
    {
      "epoch": 0.39492242595204513,
      "grad_norm": 0.09332334250211716,
      "learning_rate": 4.935393258426966e-05,
      "loss": 0.0265,
      "step": 70
    },
    {
      "epoch": 0.4513399153737659,
      "grad_norm": 0.02727678418159485,
      "learning_rate": 4.926029962546817e-05,
      "loss": 0.0258,
      "step": 80
    },
    {
      "epoch": 0.5077574047954866,
      "grad_norm": 0.0336698517203331,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 0.0252,
      "step": 90
    },
    {
      "epoch": 0.5641748942172073,
      "grad_norm": 0.03445412591099739,
      "learning_rate": 4.9073033707865176e-05,
      "loss": 0.0248,
      "step": 100
    },
    {
      "epoch": 0.5641748942172073,
      "eval_loss": 0.018952185288071632,
      "eval_runtime": 21.9351,
      "eval_samples_per_second": 2068.786,
      "eval_steps_per_second": 4.057,
      "step": 100
    },
    {
      "epoch": 0.6205923836389281,
      "grad_norm": 0.02476409077644348,
      "learning_rate": 4.8979400749063674e-05,
      "loss": 0.0243,
      "step": 110
    },
    {
      "epoch": 0.6770098730606487,
      "grad_norm": 0.02799997851252556,
      "learning_rate": 4.888576779026218e-05,
      "loss": 0.0238,
      "step": 120
    },
    {
      "epoch": 0.7334273624823695,
      "grad_norm": 0.027221741154789925,
      "learning_rate": 4.8792134831460676e-05,
      "loss": 0.0235,
      "step": 130
    },
    {
      "epoch": 0.7898448519040903,
      "grad_norm": 0.032888371497392654,
      "learning_rate": 4.869850187265918e-05,
      "loss": 0.0232,
      "step": 140
    },
    {
      "epoch": 0.846262341325811,
      "grad_norm": 0.03806062787771225,
      "learning_rate": 4.860486891385768e-05,
      "loss": 0.0229,
      "step": 150
    },
    {
      "epoch": 0.846262341325811,
      "eval_loss": 0.018513323739171028,
      "eval_runtime": 21.7457,
      "eval_samples_per_second": 2086.8,
      "eval_steps_per_second": 4.093,
      "step": 150
    },
    {
      "epoch": 0.9026798307475318,
      "grad_norm": 0.03777385503053665,
      "learning_rate": 4.8511235955056184e-05,
      "loss": 0.0225,
      "step": 160
    },
    {
      "epoch": 0.9590973201692524,
      "grad_norm": 0.018926449120044708,
      "learning_rate": 4.841760299625469e-05,
      "loss": 0.0222,
      "step": 170
    },
    {
      "epoch": 1.0112834978843441,
      "grad_norm": 0.03263242915272713,
      "learning_rate": 4.8323970037453186e-05,
      "loss": 0.0221,
      "step": 180
    },
    {
      "epoch": 1.0677009873060648,
      "grad_norm": 0.02161082625389099,
      "learning_rate": 4.823033707865169e-05,
      "loss": 0.022,
      "step": 190
    },
    {
      "epoch": 1.1241184767277856,
      "grad_norm": 0.01554177887737751,
      "learning_rate": 4.813670411985019e-05,
      "loss": 0.0221,
      "step": 200
    },
    {
      "epoch": 1.1241184767277856,
      "eval_loss": 0.018572578206658363,
      "eval_runtime": 21.2694,
      "eval_samples_per_second": 2133.535,
      "eval_steps_per_second": 4.184,
      "step": 200
    },
    {
      "epoch": 1.1805359661495063,
      "grad_norm": 0.02239982783794403,
      "learning_rate": 4.804307116104869e-05,
      "loss": 0.0218,
      "step": 210
    },
    {
      "epoch": 1.2369534555712272,
      "grad_norm": 0.01747843250632286,
      "learning_rate": 4.794943820224719e-05,
      "loss": 0.0217,
      "step": 220
    },
    {
      "epoch": 1.2933709449929478,
      "grad_norm": 0.018061120063066483,
      "learning_rate": 4.7855805243445696e-05,
      "loss": 0.0216,
      "step": 230
    },
    {
      "epoch": 1.3497884344146684,
      "grad_norm": 0.020997535437345505,
      "learning_rate": 4.7762172284644194e-05,
      "loss": 0.0215,
      "step": 240
    },
    {
      "epoch": 1.4062059238363893,
      "grad_norm": 0.01499350555241108,
      "learning_rate": 4.76685393258427e-05,
      "loss": 0.0215,
      "step": 250
    },
    {
      "epoch": 1.4062059238363893,
      "eval_loss": 0.018533123657107353,
      "eval_runtime": 21.3006,
      "eval_samples_per_second": 2130.409,
      "eval_steps_per_second": 4.178,
      "step": 250
    },
    {
      "epoch": 1.46262341325811,
      "grad_norm": 0.012851782143115997,
      "learning_rate": 4.75749063670412e-05,
      "loss": 0.0214,
      "step": 260
    },
    {
      "epoch": 1.5190409026798308,
      "grad_norm": 0.021045207977294922,
      "learning_rate": 4.74812734082397e-05,
      "loss": 0.0213,
      "step": 270
    },
    {
      "epoch": 1.5754583921015515,
      "grad_norm": 0.01665014587342739,
      "learning_rate": 4.7387640449438205e-05,
      "loss": 0.0211,
      "step": 280
    },
    {
      "epoch": 1.6318758815232721,
      "grad_norm": 0.013773582875728607,
      "learning_rate": 4.72940074906367e-05,
      "loss": 0.0211,
      "step": 290
    },
    {
      "epoch": 1.688293370944993,
      "grad_norm": 0.014658890664577484,
      "learning_rate": 4.720037453183521e-05,
      "loss": 0.021,
      "step": 300
    },
    {
      "epoch": 1.688293370944993,
      "eval_loss": 0.018360543996095657,
      "eval_runtime": 21.7337,
      "eval_samples_per_second": 2087.956,
      "eval_steps_per_second": 4.095,
      "step": 300
    },
    {
      "epoch": 1.7447108603667136,
      "grad_norm": 0.023569922894239426,
      "learning_rate": 4.7106741573033706e-05,
      "loss": 0.0209,
      "step": 310
    },
    {
      "epoch": 1.8011283497884345,
      "grad_norm": 0.023422956466674805,
      "learning_rate": 4.701310861423221e-05,
      "loss": 0.0208,
      "step": 320
    },
    {
      "epoch": 1.8575458392101551,
      "grad_norm": 0.014073513448238373,
      "learning_rate": 4.691947565543071e-05,
      "loss": 0.0208,
      "step": 330
    },
    {
      "epoch": 1.9139633286318758,
      "grad_norm": 0.02070333994925022,
      "learning_rate": 4.682584269662921e-05,
      "loss": 0.0206,
      "step": 340
    },
    {
      "epoch": 1.9703808180535967,
      "grad_norm": 0.017942607402801514,
      "learning_rate": 4.673220973782772e-05,
      "loss": 0.0206,
      "step": 350
    },
    {
      "epoch": 1.9703808180535967,
      "eval_loss": 0.017961610108613968,
      "eval_runtime": 21.1147,
      "eval_samples_per_second": 2149.169,
      "eval_steps_per_second": 4.215,
      "step": 350
    },
    {
      "epoch": 2.0225669957686883,
      "grad_norm": 0.016908738762140274,
      "learning_rate": 4.663857677902622e-05,
      "loss": 0.0205,
      "step": 360
    },
    {
      "epoch": 2.078984485190409,
      "grad_norm": 0.015428704209625721,
      "learning_rate": 4.654494382022472e-05,
      "loss": 0.0204,
      "step": 370
    },
    {
      "epoch": 2.1354019746121295,
      "grad_norm": 0.014702278189361095,
      "learning_rate": 4.6451310861423225e-05,
      "loss": 0.0199,
      "step": 380
    },
    {
      "epoch": 2.1918194640338506,
      "grad_norm": 0.016545351594686508,
      "learning_rate": 4.635767790262173e-05,
      "loss": 0.0199,
      "step": 390
    },
    {
      "epoch": 2.2482369534555713,
      "grad_norm": 0.015057934448122978,
      "learning_rate": 4.626404494382023e-05,
      "loss": 0.0196,
      "step": 400
    },
    {
      "epoch": 2.2482369534555713,
      "eval_loss": 0.0166240856051445,
      "eval_runtime": 21.1843,
      "eval_samples_per_second": 2142.108,
      "eval_steps_per_second": 4.201,
      "step": 400
    },
    {
      "epoch": 2.304654442877292,
      "grad_norm": 0.020139150321483612,
      "learning_rate": 4.617041198501873e-05,
      "loss": 0.0188,
      "step": 410
    },
    {
      "epoch": 2.3610719322990126,
      "grad_norm": 0.01967325620353222,
      "learning_rate": 4.607677902621723e-05,
      "loss": 0.0183,
      "step": 420
    },
    {
      "epoch": 2.4174894217207337,
      "grad_norm": 0.021158888936042786,
      "learning_rate": 4.5983146067415735e-05,
      "loss": 0.0177,
      "step": 430
    },
    {
      "epoch": 2.4739069111424543,
      "grad_norm": 0.02547987923026085,
      "learning_rate": 4.588951310861423e-05,
      "loss": 0.0173,
      "step": 440
    },
    {
      "epoch": 2.530324400564175,
      "grad_norm": 0.017702870070934296,
      "learning_rate": 4.579588014981274e-05,
      "loss": 0.0167,
      "step": 450
    },
    {
      "epoch": 2.530324400564175,
      "eval_loss": 0.014083314687013626,
      "eval_runtime": 21.5299,
      "eval_samples_per_second": 2107.721,
      "eval_steps_per_second": 4.134,
      "step": 450
    },
    {
      "epoch": 2.5867418899858956,
      "grad_norm": 0.02315882034599781,
      "learning_rate": 4.5702247191011235e-05,
      "loss": 0.0165,
      "step": 460
    },
    {
      "epoch": 2.6431593794076162,
      "grad_norm": 0.026839591562747955,
      "learning_rate": 4.560861423220974e-05,
      "loss": 0.0161,
      "step": 470
    },
    {
      "epoch": 2.699576868829337,
      "grad_norm": 0.01960194669663906,
      "learning_rate": 4.5514981273408244e-05,
      "loss": 0.0159,
      "step": 480
    },
    {
      "epoch": 2.755994358251058,
      "grad_norm": 0.03642432391643524,
      "learning_rate": 4.542134831460674e-05,
      "loss": 0.0157,
      "step": 490
    },
    {
      "epoch": 2.8124118476727786,
      "grad_norm": 0.024561883881688118,
      "learning_rate": 4.532771535580525e-05,
      "loss": 0.0154,
      "step": 500
    },
    {
      "epoch": 2.8124118476727786,
      "eval_loss": 0.012597457505762577,
      "eval_runtime": 20.8671,
      "eval_samples_per_second": 2174.671,
      "eval_steps_per_second": 4.265,
      "step": 500
    },
    {
      "epoch": 2.8688293370944993,
      "grad_norm": 0.015130777843296528,
      "learning_rate": 4.5234082397003745e-05,
      "loss": 0.015,
      "step": 510
    },
    {
      "epoch": 2.92524682651622,
      "grad_norm": 0.01545189693570137,
      "learning_rate": 4.514044943820225e-05,
      "loss": 0.0147,
      "step": 520
    },
    {
      "epoch": 2.981664315937941,
      "grad_norm": 0.023140862584114075,
      "learning_rate": 4.504681647940075e-05,
      "loss": 0.0144,
      "step": 530
    },
    {
      "epoch": 3.0338504936530324,
      "grad_norm": 0.03248120844364166,
      "learning_rate": 4.495318352059925e-05,
      "loss": 0.0144,
      "step": 540
    },
    {
      "epoch": 3.090267983074753,
      "grad_norm": 0.02820875495672226,
      "learning_rate": 4.485955056179775e-05,
      "loss": 0.0141,
      "step": 550
    },
    {
      "epoch": 3.090267983074753,
      "eval_loss": 0.011286101303994656,
      "eval_runtime": 21.5647,
      "eval_samples_per_second": 2104.319,
      "eval_steps_per_second": 4.127,
      "step": 550
    },
    {
      "epoch": 3.1466854724964737,
      "grad_norm": 0.01698841154575348,
      "learning_rate": 4.4765917602996254e-05,
      "loss": 0.014,
      "step": 560
    },
    {
      "epoch": 3.2031029619181948,
      "grad_norm": 0.021400514990091324,
      "learning_rate": 4.467228464419476e-05,
      "loss": 0.0138,
      "step": 570
    },
    {
      "epoch": 3.2595204513399154,
      "grad_norm": 0.0386756956577301,
      "learning_rate": 4.457865168539326e-05,
      "loss": 0.0135,
      "step": 580
    },
    {
      "epoch": 3.315937940761636,
      "grad_norm": 0.03908287361264229,
      "learning_rate": 4.448501872659177e-05,
      "loss": 0.0135,
      "step": 590
    },
    {
      "epoch": 3.3723554301833567,
      "grad_norm": 0.03193923830986023,
      "learning_rate": 4.4391385767790266e-05,
      "loss": 0.0133,
      "step": 600
    },
    {
      "epoch": 3.3723554301833567,
      "eval_loss": 0.010527210310101509,
      "eval_runtime": 21.0754,
      "eval_samples_per_second": 2153.176,
      "eval_steps_per_second": 4.223,
      "step": 600
    },
    {
      "epoch": 3.428772919605078,
      "grad_norm": 0.029896078631281853,
      "learning_rate": 4.429775280898877e-05,
      "loss": 0.013,
      "step": 610
    },
    {
      "epoch": 3.4851904090267984,
      "grad_norm": 0.019174037501215935,
      "learning_rate": 4.420411985018727e-05,
      "loss": 0.013,
      "step": 620
    },
    {
      "epoch": 3.541607898448519,
      "grad_norm": 0.015382770448923111,
      "learning_rate": 4.411048689138577e-05,
      "loss": 0.0128,
      "step": 630
    },
    {
      "epoch": 3.5980253878702397,
      "grad_norm": 0.016867946833372116,
      "learning_rate": 4.401685393258427e-05,
      "loss": 0.0126,
      "step": 640
    },
    {
      "epoch": 3.6544428772919604,
      "grad_norm": 0.013500208966434002,
      "learning_rate": 4.3923220973782776e-05,
      "loss": 0.0125,
      "step": 650
    },
    {
      "epoch": 3.6544428772919604,
      "eval_loss": 0.009905547834932804,
      "eval_runtime": 21.3731,
      "eval_samples_per_second": 2123.18,
      "eval_steps_per_second": 4.164,
      "step": 650
    },
    {
      "epoch": 3.710860366713681,
      "grad_norm": 0.014488189481198788,
      "learning_rate": 4.3829588014981274e-05,
      "loss": 0.0125,
      "step": 660
    },
    {
      "epoch": 3.767277856135402,
      "grad_norm": 0.017834968864917755,
      "learning_rate": 4.373595505617978e-05,
      "loss": 0.0123,
      "step": 670
    },
    {
      "epoch": 3.8236953455571228,
      "grad_norm": 0.01765202358365059,
      "learning_rate": 4.364232209737828e-05,
      "loss": 0.0122,
      "step": 680
    },
    {
      "epoch": 3.8801128349788434,
      "grad_norm": 0.017421020194888115,
      "learning_rate": 4.354868913857678e-05,
      "loss": 0.012,
      "step": 690
    },
    {
      "epoch": 3.936530324400564,
      "grad_norm": 0.021490279585123062,
      "learning_rate": 4.3455056179775285e-05,
      "loss": 0.0119,
      "step": 700
    },
    {
      "epoch": 3.936530324400564,
      "eval_loss": 0.009297722950577736,
      "eval_runtime": 21.3922,
      "eval_samples_per_second": 2121.283,
      "eval_steps_per_second": 4.16,
      "step": 700
    },
    {
      "epoch": 3.992947813822285,
      "grad_norm": 0.01936044543981552,
      "learning_rate": 4.336142322097378e-05,
      "loss": 0.0118,
      "step": 710
    },
    {
      "epoch": 4.0451339915373765,
      "grad_norm": 0.0207816269248724,
      "learning_rate": 4.326779026217229e-05,
      "loss": 0.0118,
      "step": 720
    },
    {
      "epoch": 4.101551480959097,
      "grad_norm": 0.014555370435118675,
      "learning_rate": 4.3174157303370786e-05,
      "loss": 0.0116,
      "step": 730
    },
    {
      "epoch": 4.157968970380818,
      "grad_norm": 0.029755746945738792,
      "learning_rate": 4.308052434456929e-05,
      "loss": 0.0117,
      "step": 740
    },
    {
      "epoch": 4.2143864598025385,
      "grad_norm": 0.018697625026106834,
      "learning_rate": 4.298689138576779e-05,
      "loss": 0.0115,
      "step": 750
    },
    {
      "epoch": 4.2143864598025385,
      "eval_loss": 0.008740430697798729,
      "eval_runtime": 21.1067,
      "eval_samples_per_second": 2149.98,
      "eval_steps_per_second": 4.217,
      "step": 750
    },
    {
      "epoch": 4.270803949224259,
      "grad_norm": 0.029936417937278748,
      "learning_rate": 4.289325842696629e-05,
      "loss": 0.0113,
      "step": 760
    },
    {
      "epoch": 4.327221438645981,
      "grad_norm": 0.022419700399041176,
      "learning_rate": 4.27996254681648e-05,
      "loss": 0.0112,
      "step": 770
    },
    {
      "epoch": 4.383638928067701,
      "grad_norm": 0.030781300738453865,
      "learning_rate": 4.2705992509363296e-05,
      "loss": 0.0111,
      "step": 780
    },
    {
      "epoch": 4.440056417489422,
      "grad_norm": 0.027933983132243156,
      "learning_rate": 4.26123595505618e-05,
      "loss": 0.011,
      "step": 790
    },
    {
      "epoch": 4.496473906911143,
      "grad_norm": 0.025403136387467384,
      "learning_rate": 4.25187265917603e-05,
      "loss": 0.011,
      "step": 800
    },
    {
      "epoch": 4.496473906911143,
      "eval_loss": 0.008197708055377007,
      "eval_runtime": 20.9812,
      "eval_samples_per_second": 2162.836,
      "eval_steps_per_second": 4.242,
      "step": 800
    },
    {
      "epoch": 4.552891396332863,
      "grad_norm": 0.023808978497982025,
      "learning_rate": 4.24250936329588e-05,
      "loss": 0.0108,
      "step": 810
    },
    {
      "epoch": 4.609308885754584,
      "grad_norm": 0.018993811681866646,
      "learning_rate": 4.23314606741573e-05,
      "loss": 0.0107,
      "step": 820
    },
    {
      "epoch": 4.6657263751763045,
      "grad_norm": 0.02095881663262844,
      "learning_rate": 4.223782771535581e-05,
      "loss": 0.0106,
      "step": 830
    },
    {
      "epoch": 4.722143864598025,
      "grad_norm": 0.024082496762275696,
      "learning_rate": 4.214419475655431e-05,
      "loss": 0.0106,
      "step": 840
    },
    {
      "epoch": 4.778561354019746,
      "grad_norm": 0.030940458178520203,
      "learning_rate": 4.2050561797752815e-05,
      "loss": 0.0104,
      "step": 850
    },
    {
      "epoch": 4.778561354019746,
      "eval_loss": 0.007769613526761532,
      "eval_runtime": 21.2699,
      "eval_samples_per_second": 2133.482,
      "eval_steps_per_second": 4.184,
      "step": 850
    },
    {
      "epoch": 4.834978843441467,
      "grad_norm": 0.03747222200036049,
      "learning_rate": 4.195692883895131e-05,
      "loss": 0.0105,
      "step": 860
    },
    {
      "epoch": 4.891396332863188,
      "grad_norm": 0.023563697934150696,
      "learning_rate": 4.186329588014982e-05,
      "loss": 0.0103,
      "step": 870
    },
    {
      "epoch": 4.947813822284909,
      "grad_norm": 0.01744735613465309,
      "learning_rate": 4.1769662921348315e-05,
      "loss": 0.0102,
      "step": 880
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.026593877002596855,
      "learning_rate": 4.167602996254682e-05,
      "loss": 0.0102,
      "step": 890
    },
    {
      "epoch": 5.056417489421721,
      "grad_norm": 0.030650760978460312,
      "learning_rate": 4.1582397003745324e-05,
      "loss": 0.0101,
      "step": 900
    },
    {
      "epoch": 5.056417489421721,
      "eval_loss": 0.007270134519785643,
      "eval_runtime": 20.9346,
      "eval_samples_per_second": 2167.652,
      "eval_steps_per_second": 4.251,
      "step": 900
    },
    {
      "epoch": 5.112834978843441,
      "grad_norm": 0.03075086511671543,
      "learning_rate": 4.148876404494382e-05,
      "loss": 0.01,
      "step": 910
    },
    {
      "epoch": 5.169252468265162,
      "grad_norm": 0.02620682865381241,
      "learning_rate": 4.139513108614233e-05,
      "loss": 0.0099,
      "step": 920
    },
    {
      "epoch": 5.225669957686883,
      "grad_norm": 0.022660821676254272,
      "learning_rate": 4.1301498127340825e-05,
      "loss": 0.0098,
      "step": 930
    },
    {
      "epoch": 5.282087447108603,
      "grad_norm": 0.018166586756706238,
      "learning_rate": 4.120786516853933e-05,
      "loss": 0.0097,
      "step": 940
    },
    {
      "epoch": 5.338504936530325,
      "grad_norm": 0.022661961615085602,
      "learning_rate": 4.111423220973783e-05,
      "loss": 0.0096,
      "step": 950
    },
    {
      "epoch": 5.338504936530325,
      "eval_loss": 0.006874055601656437,
      "eval_runtime": 20.8736,
      "eval_samples_per_second": 2173.988,
      "eval_steps_per_second": 4.264,
      "step": 950
    },
    {
      "epoch": 5.394922425952045,
      "grad_norm": 0.020209901034832,
      "learning_rate": 4.102059925093633e-05,
      "loss": 0.0094,
      "step": 960
    },
    {
      "epoch": 5.451339915373766,
      "grad_norm": 0.019179200753569603,
      "learning_rate": 4.092696629213483e-05,
      "loss": 0.0094,
      "step": 970
    },
    {
      "epoch": 5.507757404795487,
      "grad_norm": 0.024213599041104317,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 0.0092,
      "step": 980
    },
    {
      "epoch": 5.564174894217207,
      "grad_norm": 0.015986908227205276,
      "learning_rate": 4.073970037453184e-05,
      "loss": 0.0091,
      "step": 990
    },
    {
      "epoch": 5.620592383638928,
      "grad_norm": 0.02765769325196743,
      "learning_rate": 4.064606741573034e-05,
      "loss": 0.0091,
      "step": 1000
    },
    {
      "epoch": 5.620592383638928,
      "eval_loss": 0.0064880819991230965,
      "eval_runtime": 21.3183,
      "eval_samples_per_second": 2128.644,
      "eval_steps_per_second": 4.175,
      "step": 1000
    },
    {
      "epoch": 5.677009873060649,
      "grad_norm": 0.024142375215888023,
      "learning_rate": 4.055243445692884e-05,
      "loss": 0.009,
      "step": 1010
    },
    {
      "epoch": 5.733427362482369,
      "grad_norm": 0.014932522550225258,
      "learning_rate": 4.045880149812734e-05,
      "loss": 0.0088,
      "step": 1020
    },
    {
      "epoch": 5.78984485190409,
      "grad_norm": 0.012800577096641064,
      "learning_rate": 4.0365168539325844e-05,
      "loss": 0.0087,
      "step": 1030
    },
    {
      "epoch": 5.8462623413258115,
      "grad_norm": 0.011690485291182995,
      "learning_rate": 4.027153558052434e-05,
      "loss": 0.0087,
      "step": 1040
    },
    {
      "epoch": 5.902679830747532,
      "grad_norm": 0.02960655838251114,
      "learning_rate": 4.0177902621722846e-05,
      "loss": 0.0085,
      "step": 1050
    },
    {
      "epoch": 5.902679830747532,
      "eval_loss": 0.006061296444386244,
      "eval_runtime": 21.012,
      "eval_samples_per_second": 2159.668,
      "eval_steps_per_second": 4.236,
      "step": 1050
    },
    {
      "epoch": 5.959097320169253,
      "grad_norm": 0.024974534288048744,
      "learning_rate": 4.0084269662921344e-05,
      "loss": 0.0086,
      "step": 1060
    },
    {
      "epoch": 6.011283497884344,
      "grad_norm": 0.01645783893764019,
      "learning_rate": 3.9990636704119856e-05,
      "loss": 0.0085,
      "step": 1070
    },
    {
      "epoch": 6.067700987306065,
      "grad_norm": 0.01818847469985485,
      "learning_rate": 3.9897003745318354e-05,
      "loss": 0.0082,
      "step": 1080
    },
    {
      "epoch": 6.124118476727785,
      "grad_norm": 0.014619250781834126,
      "learning_rate": 3.980337078651686e-05,
      "loss": 0.0082,
      "step": 1090
    },
    {
      "epoch": 6.180535966149506,
      "grad_norm": 0.013100030831992626,
      "learning_rate": 3.970973782771536e-05,
      "loss": 0.0081,
      "step": 1100
    },
    {
      "epoch": 6.180535966149506,
      "eval_loss": 0.005773593205958605,
      "eval_runtime": 21.6578,
      "eval_samples_per_second": 2095.269,
      "eval_steps_per_second": 4.109,
      "step": 1100
    },
    {
      "epoch": 6.236953455571227,
      "grad_norm": 0.017303839325904846,
      "learning_rate": 3.961610486891386e-05,
      "loss": 0.008,
      "step": 1110
    },
    {
      "epoch": 6.293370944992947,
      "grad_norm": 0.01703648455440998,
      "learning_rate": 3.9522471910112365e-05,
      "loss": 0.008,
      "step": 1120
    },
    {
      "epoch": 6.349788434414669,
      "grad_norm": 0.018260199576616287,
      "learning_rate": 3.942883895131086e-05,
      "loss": 0.0079,
      "step": 1130
    },
    {
      "epoch": 6.4062059238363895,
      "grad_norm": 0.016145754605531693,
      "learning_rate": 3.933520599250937e-05,
      "loss": 0.0078,
      "step": 1140
    },
    {
      "epoch": 6.46262341325811,
      "grad_norm": 0.011277265846729279,
      "learning_rate": 3.9241573033707866e-05,
      "loss": 0.0078,
      "step": 1150
    },
    {
      "epoch": 6.46262341325811,
      "eval_loss": 0.005585096776485443,
      "eval_runtime": 21.1545,
      "eval_samples_per_second": 2145.121,
      "eval_steps_per_second": 4.207,
      "step": 1150
    },
    {
      "epoch": 6.519040902679831,
      "grad_norm": 0.012285794131457806,
      "learning_rate": 3.914794007490637e-05,
      "loss": 0.0078,
      "step": 1160
    },
    {
      "epoch": 6.5754583921015515,
      "grad_norm": 0.017460467293858528,
      "learning_rate": 3.905430711610487e-05,
      "loss": 0.0077,
      "step": 1170
    },
    {
      "epoch": 6.631875881523272,
      "grad_norm": 0.02127382904291153,
      "learning_rate": 3.896067415730337e-05,
      "loss": 0.0078,
      "step": 1180
    },
    {
      "epoch": 6.688293370944993,
      "grad_norm": 0.016763564199209213,
      "learning_rate": 3.886704119850188e-05,
      "loss": 0.0077,
      "step": 1190
    },
    {
      "epoch": 6.744710860366713,
      "grad_norm": 0.017938047647476196,
      "learning_rate": 3.8773408239700376e-05,
      "loss": 0.0077,
      "step": 1200
    },
    {
      "epoch": 6.744710860366713,
      "eval_loss": 0.0054189469665288925,
      "eval_runtime": 21.3384,
      "eval_samples_per_second": 2126.631,
      "eval_steps_per_second": 4.171,
      "step": 1200
    },
    {
      "epoch": 6.801128349788434,
      "grad_norm": 0.012490853667259216,
      "learning_rate": 3.867977528089888e-05,
      "loss": 0.0076,
      "step": 1210
    },
    {
      "epoch": 6.857545839210156,
      "grad_norm": 0.01574668660759926,
      "learning_rate": 3.858614232209738e-05,
      "loss": 0.0076,
      "step": 1220
    },
    {
      "epoch": 6.913963328631876,
      "grad_norm": 0.01711343228816986,
      "learning_rate": 3.849250936329588e-05,
      "loss": 0.0076,
      "step": 1230
    },
    {
      "epoch": 6.970380818053597,
      "grad_norm": 0.015273108147084713,
      "learning_rate": 3.839887640449438e-05,
      "loss": 0.0074,
      "step": 1240
    },
    {
      "epoch": 7.022566995768688,
      "grad_norm": 0.012235729023814201,
      "learning_rate": 3.8305243445692885e-05,
      "loss": 0.0075,
      "step": 1250
    },
    {
      "epoch": 7.022566995768688,
      "eval_loss": 0.005291837267577648,
      "eval_runtime": 21.2957,
      "eval_samples_per_second": 2130.895,
      "eval_steps_per_second": 4.179,
      "step": 1250
    },
    {
      "epoch": 7.078984485190409,
      "grad_norm": 0.012248043902218342,
      "learning_rate": 3.821161048689138e-05,
      "loss": 0.0074,
      "step": 1260
    },
    {
      "epoch": 7.1354019746121295,
      "grad_norm": 0.020568571984767914,
      "learning_rate": 3.811797752808989e-05,
      "loss": 0.0074,
      "step": 1270
    },
    {
      "epoch": 7.19181946403385,
      "grad_norm": 0.022382309660315514,
      "learning_rate": 3.802434456928839e-05,
      "loss": 0.0074,
      "step": 1280
    },
    {
      "epoch": 7.248236953455571,
      "grad_norm": 0.023984454572200775,
      "learning_rate": 3.793071161048689e-05,
      "loss": 0.0072,
      "step": 1290
    },
    {
      "epoch": 7.304654442877292,
      "grad_norm": 0.013736228458583355,
      "learning_rate": 3.7837078651685395e-05,
      "loss": 0.0073,
      "step": 1300
    },
    {
      "epoch": 7.304654442877292,
      "eval_loss": 0.005182816181331873,
      "eval_runtime": 21.3949,
      "eval_samples_per_second": 2121.024,
      "eval_steps_per_second": 4.16,
      "step": 1300
    },
    {
      "epoch": 7.361071932299013,
      "grad_norm": 0.01303072925657034,
      "learning_rate": 3.774344569288389e-05,
      "loss": 0.0072,
      "step": 1310
    },
    {
      "epoch": 7.417489421720734,
      "grad_norm": 0.012560018338263035,
      "learning_rate": 3.7649812734082404e-05,
      "loss": 0.0072,
      "step": 1320
    },
    {
      "epoch": 7.473906911142454,
      "grad_norm": 0.01123377401381731,
      "learning_rate": 3.75561797752809e-05,
      "loss": 0.0072,
      "step": 1330
    },
    {
      "epoch": 7.530324400564175,
      "grad_norm": 0.01569744385778904,
      "learning_rate": 3.746254681647941e-05,
      "loss": 0.0072,
      "step": 1340
    },
    {
      "epoch": 7.586741889985896,
      "grad_norm": 0.014418231323361397,
      "learning_rate": 3.7368913857677905e-05,
      "loss": 0.0072,
      "step": 1350
    },
    {
      "epoch": 7.586741889985896,
      "eval_loss": 0.005123802460730076,
      "eval_runtime": 21.0141,
      "eval_samples_per_second": 2159.459,
      "eval_steps_per_second": 4.235,
      "step": 1350
    },
    {
      "epoch": 7.643159379407616,
      "grad_norm": 0.01573084481060505,
      "learning_rate": 3.727528089887641e-05,
      "loss": 0.0071,
      "step": 1360
    },
    {
      "epoch": 7.699576868829337,
      "grad_norm": 0.02041197009384632,
      "learning_rate": 3.718164794007491e-05,
      "loss": 0.0072,
      "step": 1370
    },
    {
      "epoch": 7.7559943582510575,
      "grad_norm": 0.015854747965931892,
      "learning_rate": 3.708801498127341e-05,
      "loss": 0.0071,
      "step": 1380
    },
    {
      "epoch": 7.812411847672778,
      "grad_norm": 0.014464068226516247,
      "learning_rate": 3.699438202247191e-05,
      "loss": 0.007,
      "step": 1390
    },
    {
      "epoch": 7.8688293370945,
      "grad_norm": 0.018940560519695282,
      "learning_rate": 3.6900749063670414e-05,
      "loss": 0.007,
      "step": 1400
    },
    {
      "epoch": 7.8688293370945,
      "eval_loss": 0.005084376782178879,
      "eval_runtime": 21.1787,
      "eval_samples_per_second": 2142.668,
      "eval_steps_per_second": 4.202,
      "step": 1400
    },
    {
      "epoch": 7.92524682651622,
      "grad_norm": 0.015576996840536594,
      "learning_rate": 3.680711610486892e-05,
      "loss": 0.0071,
      "step": 1410
    },
    {
      "epoch": 7.981664315937941,
      "grad_norm": 0.010908462107181549,
      "learning_rate": 3.671348314606742e-05,
      "loss": 0.007,
      "step": 1420
    },
    {
      "epoch": 8.033850493653032,
      "grad_norm": 0.023926032707095146,
      "learning_rate": 3.661985018726592e-05,
      "loss": 0.007,
      "step": 1430
    },
    {
      "epoch": 8.090267983074753,
      "grad_norm": 0.0178593248128891,
      "learning_rate": 3.652621722846442e-05,
      "loss": 0.0069,
      "step": 1440
    },
    {
      "epoch": 8.146685472496474,
      "grad_norm": 0.019306141883134842,
      "learning_rate": 3.6432584269662924e-05,
      "loss": 0.0069,
      "step": 1450
    },
    {
      "epoch": 8.146685472496474,
      "eval_loss": 0.004982291255146265,
      "eval_runtime": 21.5724,
      "eval_samples_per_second": 2103.569,
      "eval_steps_per_second": 4.126,
      "step": 1450
    },
    {
      "epoch": 8.203102961918194,
      "grad_norm": 0.01914423704147339,
      "learning_rate": 3.633895131086142e-05,
      "loss": 0.0069,
      "step": 1460
    },
    {
      "epoch": 8.259520451339915,
      "grad_norm": 0.016987193375825882,
      "learning_rate": 3.6245318352059926e-05,
      "loss": 0.007,
      "step": 1470
    },
    {
      "epoch": 8.315937940761636,
      "grad_norm": 0.01267126202583313,
      "learning_rate": 3.6151685393258424e-05,
      "loss": 0.0069,
      "step": 1480
    },
    {
      "epoch": 8.372355430183356,
      "grad_norm": 0.018554367125034332,
      "learning_rate": 3.605805243445693e-05,
      "loss": 0.0069,
      "step": 1490
    },
    {
      "epoch": 8.428772919605077,
      "grad_norm": 0.014128359034657478,
      "learning_rate": 3.5964419475655434e-05,
      "loss": 0.0069,
      "step": 1500
    },
    {
      "epoch": 8.428772919605077,
      "eval_loss": 0.004890951327979565,
      "eval_runtime": 20.9218,
      "eval_samples_per_second": 2168.981,
      "eval_steps_per_second": 4.254,
      "step": 1500
    },
    {
      "epoch": 8.485190409026798,
      "grad_norm": 0.011660284362733364,
      "learning_rate": 3.587078651685393e-05,
      "loss": 0.0069,
      "step": 1510
    },
    {
      "epoch": 8.541607898448518,
      "grad_norm": 0.017116233706474304,
      "learning_rate": 3.5777153558052436e-05,
      "loss": 0.0069,
      "step": 1520
    },
    {
      "epoch": 8.59802538787024,
      "grad_norm": 0.011649367399513721,
      "learning_rate": 3.5683520599250934e-05,
      "loss": 0.0068,
      "step": 1530
    },
    {
      "epoch": 8.654442877291961,
      "grad_norm": 0.014288690872490406,
      "learning_rate": 3.558988764044944e-05,
      "loss": 0.0068,
      "step": 1540
    },
    {
      "epoch": 8.710860366713682,
      "grad_norm": 0.010825421661138535,
      "learning_rate": 3.5496254681647937e-05,
      "loss": 0.0067,
      "step": 1550
    },
    {
      "epoch": 8.710860366713682,
      "eval_loss": 0.004830225370824337,
      "eval_runtime": 21.3065,
      "eval_samples_per_second": 2129.815,
      "eval_steps_per_second": 4.177,
      "step": 1550
    },
    {
      "epoch": 8.767277856135403,
      "grad_norm": 0.013619519770145416,
      "learning_rate": 3.540262172284645e-05,
      "loss": 0.0067,
      "step": 1560
    },
    {
      "epoch": 8.823695345557123,
      "grad_norm": 0.01367915142327547,
      "learning_rate": 3.5308988764044946e-05,
      "loss": 0.0068,
      "step": 1570
    },
    {
      "epoch": 8.880112834978844,
      "grad_norm": 0.012355136685073376,
      "learning_rate": 3.521535580524345e-05,
      "loss": 0.0068,
      "step": 1580
    },
    {
      "epoch": 8.936530324400564,
      "grad_norm": 0.012906900607049465,
      "learning_rate": 3.512172284644195e-05,
      "loss": 0.0067,
      "step": 1590
    },
    {
      "epoch": 8.992947813822285,
      "grad_norm": 0.010343266651034355,
      "learning_rate": 3.502808988764045e-05,
      "loss": 0.0067,
      "step": 1600
    },
    {
      "epoch": 8.992947813822285,
      "eval_loss": 0.004802713170647621,
      "eval_runtime": 20.8883,
      "eval_samples_per_second": 2172.457,
      "eval_steps_per_second": 4.261,
      "step": 1600
    },
    {
      "epoch": 9.045133991537377,
      "grad_norm": 0.012143158353865147,
      "learning_rate": 3.493445692883896e-05,
      "loss": 0.0067,
      "step": 1610
    },
    {
      "epoch": 9.101551480959097,
      "grad_norm": 0.013631363399326801,
      "learning_rate": 3.4840823970037456e-05,
      "loss": 0.0066,
      "step": 1620
    },
    {
      "epoch": 9.157968970380818,
      "grad_norm": 0.012880777940154076,
      "learning_rate": 3.474719101123596e-05,
      "loss": 0.0066,
      "step": 1630
    },
    {
      "epoch": 9.214386459802538,
      "grad_norm": 0.012819216586649418,
      "learning_rate": 3.465355805243446e-05,
      "loss": 0.0067,
      "step": 1640
    },
    {
      "epoch": 9.270803949224259,
      "grad_norm": 0.028383197262883186,
      "learning_rate": 3.455992509363296e-05,
      "loss": 0.0067,
      "step": 1650
    },
    {
      "epoch": 9.270803949224259,
      "eval_loss": 0.004801029805094004,
      "eval_runtime": 20.7725,
      "eval_samples_per_second": 2184.566,
      "eval_steps_per_second": 4.285,
      "step": 1650
    },
    {
      "epoch": 9.32722143864598,
      "grad_norm": 0.017430802807211876,
      "learning_rate": 3.446629213483146e-05,
      "loss": 0.0067,
      "step": 1660
    },
    {
      "epoch": 9.3836389280677,
      "grad_norm": 0.014267783612012863,
      "learning_rate": 3.4372659176029965e-05,
      "loss": 0.0067,
      "step": 1670
    },
    {
      "epoch": 9.440056417489421,
      "grad_norm": 0.016845911741256714,
      "learning_rate": 3.427902621722846e-05,
      "loss": 0.0067,
      "step": 1680
    },
    {
      "epoch": 9.496473906911142,
      "grad_norm": 0.022262506186962128,
      "learning_rate": 3.418539325842697e-05,
      "loss": 0.0066,
      "step": 1690
    },
    {
      "epoch": 9.552891396332864,
      "grad_norm": 0.010992736555635929,
      "learning_rate": 3.409176029962547e-05,
      "loss": 0.0067,
      "step": 1700
    },
    {
      "epoch": 9.552891396332864,
      "eval_loss": 0.004675688222050667,
      "eval_runtime": 20.779,
      "eval_samples_per_second": 2183.89,
      "eval_steps_per_second": 4.283,
      "step": 1700
    },
    {
      "epoch": 9.609308885754585,
      "grad_norm": 0.017478927969932556,
      "learning_rate": 3.399812734082397e-05,
      "loss": 0.0066,
      "step": 1710
    },
    {
      "epoch": 9.665726375176305,
      "grad_norm": 0.015219570137560368,
      "learning_rate": 3.3904494382022475e-05,
      "loss": 0.0067,
      "step": 1720
    },
    {
      "epoch": 9.722143864598026,
      "grad_norm": 0.027826987206935883,
      "learning_rate": 3.381086142322097e-05,
      "loss": 0.0065,
      "step": 1730
    },
    {
      "epoch": 9.778561354019747,
      "grad_norm": 0.023656075820326805,
      "learning_rate": 3.371722846441948e-05,
      "loss": 0.0065,
      "step": 1740
    },
    {
      "epoch": 9.834978843441467,
      "grad_norm": 0.021533703431487083,
      "learning_rate": 3.3623595505617975e-05,
      "loss": 0.0065,
      "step": 1750
    },
    {
      "epoch": 9.834978843441467,
      "eval_loss": 0.004707383457571268,
      "eval_runtime": 21.1507,
      "eval_samples_per_second": 2145.513,
      "eval_steps_per_second": 4.208,
      "step": 1750
    },
    {
      "epoch": 9.891396332863188,
      "grad_norm": 0.025932930409908295,
      "learning_rate": 3.352996254681648e-05,
      "loss": 0.0066,
      "step": 1760
    },
    {
      "epoch": 9.947813822284909,
      "grad_norm": 0.015616868622601032,
      "learning_rate": 3.343632958801498e-05,
      "loss": 0.0066,
      "step": 1770
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.018188707530498505,
      "learning_rate": 3.334269662921348e-05,
      "loss": 0.0064,
      "step": 1780
    },
    {
      "epoch": 10.05641748942172,
      "grad_norm": 0.013109365478157997,
      "learning_rate": 3.324906367041199e-05,
      "loss": 0.0066,
      "step": 1790
    },
    {
      "epoch": 10.112834978843441,
      "grad_norm": 0.020196350291371346,
      "learning_rate": 3.315543071161049e-05,
      "loss": 0.0065,
      "step": 1800
    },
    {
      "epoch": 10.112834978843441,
      "eval_loss": 0.00465179979801178,
      "eval_runtime": 21.2985,
      "eval_samples_per_second": 2130.622,
      "eval_steps_per_second": 4.179,
      "step": 1800
    },
    {
      "epoch": 10.169252468265162,
      "grad_norm": 0.015996994450688362,
      "learning_rate": 3.306179775280899e-05,
      "loss": 0.0065,
      "step": 1810
    },
    {
      "epoch": 10.225669957686883,
      "grad_norm": 0.021793605759739876,
      "learning_rate": 3.2968164794007494e-05,
      "loss": 0.0065,
      "step": 1820
    },
    {
      "epoch": 10.282087447108603,
      "grad_norm": 0.016816219314932823,
      "learning_rate": 3.2874531835206e-05,
      "loss": 0.0066,
      "step": 1830
    },
    {
      "epoch": 10.338504936530324,
      "grad_norm": 0.02060149796307087,
      "learning_rate": 3.27808988764045e-05,
      "loss": 0.0065,
      "step": 1840
    },
    {
      "epoch": 10.394922425952045,
      "grad_norm": 0.012707698158919811,
      "learning_rate": 3.2687265917603e-05,
      "loss": 0.0065,
      "step": 1850
    },
    {
      "epoch": 10.394922425952045,
      "eval_loss": 0.004651994910091162,
      "eval_runtime": 21.285,
      "eval_samples_per_second": 2131.974,
      "eval_steps_per_second": 4.181,
      "step": 1850
    },
    {
      "epoch": 10.451339915373765,
      "grad_norm": 0.011690890416502953,
      "learning_rate": 3.25936329588015e-05,
      "loss": 0.0065,
      "step": 1860
    },
    {
      "epoch": 10.507757404795486,
      "grad_norm": 0.012477191165089607,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.0065,
      "step": 1870
    },
    {
      "epoch": 10.564174894217206,
      "grad_norm": 0.015425261110067368,
      "learning_rate": 3.24063670411985e-05,
      "loss": 0.0064,
      "step": 1880
    },
    {
      "epoch": 10.620592383638929,
      "grad_norm": 0.013833786360919476,
      "learning_rate": 3.2312734082397006e-05,
      "loss": 0.0065,
      "step": 1890
    },
    {
      "epoch": 10.67700987306065,
      "grad_norm": 0.01737908646464348,
      "learning_rate": 3.2219101123595504e-05,
      "loss": 0.0064,
      "step": 1900
    },
    {
      "epoch": 10.67700987306065,
      "eval_loss": 0.0046126325614750385,
      "eval_runtime": 21.507,
      "eval_samples_per_second": 2109.963,
      "eval_steps_per_second": 4.138,
      "step": 1900
    },
    {
      "epoch": 10.73342736248237,
      "grad_norm": 0.01593322865664959,
      "learning_rate": 3.212546816479401e-05,
      "loss": 0.0065,
      "step": 1910
    },
    {
      "epoch": 10.78984485190409,
      "grad_norm": 0.011335980147123337,
      "learning_rate": 3.2031835205992514e-05,
      "loss": 0.0065,
      "step": 1920
    },
    {
      "epoch": 10.846262341325811,
      "grad_norm": 0.019695909693837166,
      "learning_rate": 3.193820224719101e-05,
      "loss": 0.0065,
      "step": 1930
    },
    {
      "epoch": 10.902679830747532,
      "grad_norm": 0.016072889789938927,
      "learning_rate": 3.1844569288389516e-05,
      "loss": 0.0065,
      "step": 1940
    },
    {
      "epoch": 10.959097320169253,
      "grad_norm": 0.019052967429161072,
      "learning_rate": 3.1750936329588014e-05,
      "loss": 0.0064,
      "step": 1950
    },
    {
      "epoch": 10.959097320169253,
      "eval_loss": 0.004646276589483023,
      "eval_runtime": 20.9987,
      "eval_samples_per_second": 2161.036,
      "eval_steps_per_second": 4.238,
      "step": 1950
    },
    {
      "epoch": 11.011283497884344,
      "grad_norm": 0.015808746218681335,
      "learning_rate": 3.165730337078652e-05,
      "loss": 0.0064,
      "step": 1960
    },
    {
      "epoch": 11.067700987306065,
      "grad_norm": 0.016201097518205643,
      "learning_rate": 3.1563670411985017e-05,
      "loss": 0.0065,
      "step": 1970
    },
    {
      "epoch": 11.124118476727785,
      "grad_norm": 0.012572867795825005,
      "learning_rate": 3.147003745318352e-05,
      "loss": 0.0064,
      "step": 1980
    },
    {
      "epoch": 11.180535966149506,
      "grad_norm": 0.011505397036671638,
      "learning_rate": 3.137640449438202e-05,
      "loss": 0.0064,
      "step": 1990
    },
    {
      "epoch": 11.236953455571227,
      "grad_norm": 0.009687098674476147,
      "learning_rate": 3.1282771535580524e-05,
      "loss": 0.0064,
      "step": 2000
    },
    {
      "epoch": 11.236953455571227,
      "eval_loss": 0.004576800856739283,
      "eval_runtime": 20.6707,
      "eval_samples_per_second": 2195.33,
      "eval_steps_per_second": 4.306,
      "step": 2000
    },
    {
      "epoch": 11.293370944992947,
      "grad_norm": 0.020885024219751358,
      "learning_rate": 3.118913857677903e-05,
      "loss": 0.0063,
      "step": 2010
    },
    {
      "epoch": 11.349788434414668,
      "grad_norm": 0.014757586643099785,
      "learning_rate": 3.1095505617977526e-05,
      "loss": 0.0065,
      "step": 2020
    },
    {
      "epoch": 11.406205923836389,
      "grad_norm": 0.015928052365779877,
      "learning_rate": 3.100187265917603e-05,
      "loss": 0.0064,
      "step": 2030
    },
    {
      "epoch": 11.46262341325811,
      "grad_norm": 0.015213146805763245,
      "learning_rate": 3.0908239700374535e-05,
      "loss": 0.0063,
      "step": 2040
    },
    {
      "epoch": 11.51904090267983,
      "grad_norm": 0.011518577113747597,
      "learning_rate": 3.081460674157304e-05,
      "loss": 0.0063,
      "step": 2050
    },
    {
      "epoch": 11.51904090267983,
      "eval_loss": 0.004558892920613289,
      "eval_runtime": 21.3287,
      "eval_samples_per_second": 2127.601,
      "eval_steps_per_second": 4.173,
      "step": 2050
    },
    {
      "epoch": 11.575458392101552,
      "grad_norm": 0.015476156957447529,
      "learning_rate": 3.072097378277154e-05,
      "loss": 0.0063,
      "step": 2060
    },
    {
      "epoch": 11.631875881523273,
      "grad_norm": 0.01561888586729765,
      "learning_rate": 3.062734082397004e-05,
      "loss": 0.0063,
      "step": 2070
    },
    {
      "epoch": 11.688293370944994,
      "grad_norm": 0.014149009250104427,
      "learning_rate": 3.053370786516854e-05,
      "loss": 0.0063,
      "step": 2080
    },
    {
      "epoch": 11.744710860366714,
      "grad_norm": 0.020229818299412727,
      "learning_rate": 3.0440074906367045e-05,
      "loss": 0.0064,
      "step": 2090
    },
    {
      "epoch": 11.801128349788435,
      "grad_norm": 0.014061673544347286,
      "learning_rate": 3.0346441947565546e-05,
      "loss": 0.0063,
      "step": 2100
    },
    {
      "epoch": 11.801128349788435,
      "eval_loss": 0.004604502581059933,
      "eval_runtime": 21.2099,
      "eval_samples_per_second": 2139.517,
      "eval_steps_per_second": 4.196,
      "step": 2100
    },
    {
      "epoch": 11.857545839210156,
      "grad_norm": 0.01722067780792713,
      "learning_rate": 3.0252808988764048e-05,
      "loss": 0.0063,
      "step": 2110
    },
    {
      "epoch": 11.913963328631876,
      "grad_norm": 0.01037465501576662,
      "learning_rate": 3.015917602996255e-05,
      "loss": 0.0064,
      "step": 2120
    },
    {
      "epoch": 11.970380818053597,
      "grad_norm": 0.01195941399782896,
      "learning_rate": 3.006554307116105e-05,
      "loss": 0.0064,
      "step": 2130
    },
    {
      "epoch": 12.022566995768688,
      "grad_norm": 0.01969914697110653,
      "learning_rate": 2.997191011235955e-05,
      "loss": 0.0064,
      "step": 2140
    },
    {
      "epoch": 12.078984485190409,
      "grad_norm": 0.015269458293914795,
      "learning_rate": 2.9878277153558053e-05,
      "loss": 0.0064,
      "step": 2150
    },
    {
      "epoch": 12.078984485190409,
      "eval_loss": 0.0045892237685620785,
      "eval_runtime": 20.8568,
      "eval_samples_per_second": 2175.744,
      "eval_steps_per_second": 4.267,
      "step": 2150
    },
    {
      "epoch": 12.13540197461213,
      "grad_norm": 0.02039646916091442,
      "learning_rate": 2.9784644194756557e-05,
      "loss": 0.0063,
      "step": 2160
    },
    {
      "epoch": 12.19181946403385,
      "grad_norm": 0.015419473871588707,
      "learning_rate": 2.969101123595506e-05,
      "loss": 0.0063,
      "step": 2170
    },
    {
      "epoch": 12.24823695345557,
      "grad_norm": 0.019573582336306572,
      "learning_rate": 2.959737827715356e-05,
      "loss": 0.0064,
      "step": 2180
    },
    {
      "epoch": 12.304654442877291,
      "grad_norm": 0.013469052501022816,
      "learning_rate": 2.950374531835206e-05,
      "loss": 0.0063,
      "step": 2190
    },
    {
      "epoch": 12.361071932299012,
      "grad_norm": 0.010105031542479992,
      "learning_rate": 2.9410112359550562e-05,
      "loss": 0.0064,
      "step": 2200
    },
    {
      "epoch": 12.361071932299012,
      "eval_loss": 0.004546666517853737,
      "eval_runtime": 21.075,
      "eval_samples_per_second": 2153.217,
      "eval_steps_per_second": 4.223,
      "step": 2200
    },
    {
      "epoch": 12.417489421720733,
      "grad_norm": 0.012010211125016212,
      "learning_rate": 2.9316479400749064e-05,
      "loss": 0.0063,
      "step": 2210
    },
    {
      "epoch": 12.473906911142453,
      "grad_norm": 0.012946588918566704,
      "learning_rate": 2.9222846441947565e-05,
      "loss": 0.0064,
      "step": 2220
    },
    {
      "epoch": 12.530324400564174,
      "grad_norm": 0.012060638517141342,
      "learning_rate": 2.9129213483146066e-05,
      "loss": 0.0062,
      "step": 2230
    },
    {
      "epoch": 12.586741889985895,
      "grad_norm": 0.012806815095245838,
      "learning_rate": 2.9035580524344567e-05,
      "loss": 0.0062,
      "step": 2240
    },
    {
      "epoch": 12.643159379407617,
      "grad_norm": 0.013766921125352383,
      "learning_rate": 2.8941947565543072e-05,
      "loss": 0.0063,
      "step": 2250
    },
    {
      "epoch": 12.643159379407617,
      "eval_loss": 0.004507353063672781,
      "eval_runtime": 21.5255,
      "eval_samples_per_second": 2108.149,
      "eval_steps_per_second": 4.135,
      "step": 2250
    },
    {
      "epoch": 12.699576868829338,
      "grad_norm": 0.01880798675119877,
      "learning_rate": 2.8848314606741573e-05,
      "loss": 0.0063,
      "step": 2260
    },
    {
      "epoch": 12.755994358251058,
      "grad_norm": 0.012608506716787815,
      "learning_rate": 2.8754681647940075e-05,
      "loss": 0.0064,
      "step": 2270
    },
    {
      "epoch": 12.812411847672779,
      "grad_norm": 0.015282927080988884,
      "learning_rate": 2.8661048689138576e-05,
      "loss": 0.0063,
      "step": 2280
    },
    {
      "epoch": 12.8688293370945,
      "grad_norm": 0.01353332120925188,
      "learning_rate": 2.8567415730337084e-05,
      "loss": 0.0063,
      "step": 2290
    },
    {
      "epoch": 12.92524682651622,
      "grad_norm": 0.015107137151062489,
      "learning_rate": 2.8473782771535585e-05,
      "loss": 0.0063,
      "step": 2300
    },
    {
      "epoch": 12.92524682651622,
      "eval_loss": 0.004512757994234562,
      "eval_runtime": 20.6818,
      "eval_samples_per_second": 2194.15,
      "eval_steps_per_second": 4.303,
      "step": 2300
    },
    {
      "epoch": 12.981664315937941,
      "grad_norm": 0.01714223437011242,
      "learning_rate": 2.8380149812734086e-05,
      "loss": 0.0062,
      "step": 2310
    },
    {
      "epoch": 13.033850493653032,
      "grad_norm": 0.015821941196918488,
      "learning_rate": 2.8286516853932588e-05,
      "loss": 0.0063,
      "step": 2320
    },
    {
      "epoch": 13.090267983074753,
      "grad_norm": 0.014420556835830212,
      "learning_rate": 2.819288389513109e-05,
      "loss": 0.0063,
      "step": 2330
    },
    {
      "epoch": 13.146685472496474,
      "grad_norm": 0.018170109018683434,
      "learning_rate": 2.809925093632959e-05,
      "loss": 0.0064,
      "step": 2340
    },
    {
      "epoch": 13.203102961918194,
      "grad_norm": 0.020119309425354004,
      "learning_rate": 2.800561797752809e-05,
      "loss": 0.0062,
      "step": 2350
    },
    {
      "epoch": 13.203102961918194,
      "eval_loss": 0.004525270778685808,
      "eval_runtime": 20.9499,
      "eval_samples_per_second": 2166.075,
      "eval_steps_per_second": 4.248,
      "step": 2350
    },
    {
      "epoch": 13.259520451339915,
      "grad_norm": 0.011398827657103539,
      "learning_rate": 2.7911985018726593e-05,
      "loss": 0.0062,
      "step": 2360
    },
    {
      "epoch": 13.315937940761636,
      "grad_norm": 0.010532180778682232,
      "learning_rate": 2.7818352059925097e-05,
      "loss": 0.0062,
      "step": 2370
    },
    {
      "epoch": 13.372355430183356,
      "grad_norm": 0.01131497137248516,
      "learning_rate": 2.77247191011236e-05,
      "loss": 0.0063,
      "step": 2380
    },
    {
      "epoch": 13.428772919605077,
      "grad_norm": 0.010655902326107025,
      "learning_rate": 2.76310861423221e-05,
      "loss": 0.0062,
      "step": 2390
    },
    {
      "epoch": 13.485190409026798,
      "grad_norm": 0.015484497882425785,
      "learning_rate": 2.75374531835206e-05,
      "loss": 0.0063,
      "step": 2400
    },
    {
      "epoch": 13.485190409026798,
      "eval_loss": 0.004492981359362602,
      "eval_runtime": 21.5974,
      "eval_samples_per_second": 2101.129,
      "eval_steps_per_second": 4.121,
      "step": 2400
    },
    {
      "epoch": 13.541607898448518,
      "grad_norm": 0.009953845292329788,
      "learning_rate": 2.7443820224719102e-05,
      "loss": 0.0062,
      "step": 2410
    },
    {
      "epoch": 13.59802538787024,
      "grad_norm": 0.012630117125809193,
      "learning_rate": 2.7350187265917604e-05,
      "loss": 0.0062,
      "step": 2420
    },
    {
      "epoch": 13.654442877291961,
      "grad_norm": 0.009602540172636509,
      "learning_rate": 2.7256554307116105e-05,
      "loss": 0.0063,
      "step": 2430
    },
    {
      "epoch": 13.710860366713682,
      "grad_norm": 0.014588512480258942,
      "learning_rate": 2.7162921348314606e-05,
      "loss": 0.0062,
      "step": 2440
    },
    {
      "epoch": 13.767277856135403,
      "grad_norm": 0.011016182601451874,
      "learning_rate": 2.7069288389513107e-05,
      "loss": 0.0062,
      "step": 2450
    },
    {
      "epoch": 13.767277856135403,
      "eval_loss": 0.00445971405133605,
      "eval_runtime": 20.9766,
      "eval_samples_per_second": 2163.32,
      "eval_steps_per_second": 4.243,
      "step": 2450
    },
    {
      "epoch": 13.823695345557123,
      "grad_norm": 0.017476949840784073,
      "learning_rate": 2.6975655430711612e-05,
      "loss": 0.0062,
      "step": 2460
    },
    {
      "epoch": 13.880112834978844,
      "grad_norm": 0.014773932285606861,
      "learning_rate": 2.6882022471910113e-05,
      "loss": 0.0062,
      "step": 2470
    },
    {
      "epoch": 13.936530324400564,
      "grad_norm": 0.014127755537629128,
      "learning_rate": 2.6788389513108615e-05,
      "loss": 0.0061,
      "step": 2480
    },
    {
      "epoch": 13.992947813822285,
      "grad_norm": 0.01201949268579483,
      "learning_rate": 2.6694756554307116e-05,
      "loss": 0.0062,
      "step": 2490
    },
    {
      "epoch": 14.045133991537377,
      "grad_norm": 0.020349791273474693,
      "learning_rate": 2.6601123595505617e-05,
      "loss": 0.0062,
      "step": 2500
    },
    {
      "epoch": 14.045133991537377,
      "eval_loss": 0.004469245206564665,
      "eval_runtime": 21.5391,
      "eval_samples_per_second": 2106.824,
      "eval_steps_per_second": 4.132,
      "step": 2500
    },
    {
      "epoch": 14.101551480959097,
      "grad_norm": 0.013978138566017151,
      "learning_rate": 2.650749063670412e-05,
      "loss": 0.0062,
      "step": 2510
    },
    {
      "epoch": 14.157968970380818,
      "grad_norm": 0.0213154423981905,
      "learning_rate": 2.641385767790262e-05,
      "loss": 0.0062,
      "step": 2520
    },
    {
      "epoch": 14.214386459802538,
      "grad_norm": 0.016814645379781723,
      "learning_rate": 2.6320224719101128e-05,
      "loss": 0.0062,
      "step": 2530
    },
    {
      "epoch": 14.270803949224259,
      "grad_norm": 0.015316328033804893,
      "learning_rate": 2.622659176029963e-05,
      "loss": 0.0062,
      "step": 2540
    },
    {
      "epoch": 14.32722143864598,
      "grad_norm": 0.013064057566225529,
      "learning_rate": 2.613295880149813e-05,
      "loss": 0.0061,
      "step": 2550
    },
    {
      "epoch": 14.32722143864598,
      "eval_loss": 0.004452412482351065,
      "eval_runtime": 21.0771,
      "eval_samples_per_second": 2153.0,
      "eval_steps_per_second": 4.223,
      "step": 2550
    },
    {
      "epoch": 14.3836389280677,
      "grad_norm": 0.014144365675747395,
      "learning_rate": 2.603932584269663e-05,
      "loss": 0.0061,
      "step": 2560
    },
    {
      "epoch": 14.440056417489421,
      "grad_norm": 0.014608560130000114,
      "learning_rate": 2.5945692883895133e-05,
      "loss": 0.0061,
      "step": 2570
    },
    {
      "epoch": 14.496473906911142,
      "grad_norm": 0.0125300707295537,
      "learning_rate": 2.5852059925093637e-05,
      "loss": 0.0062,
      "step": 2580
    },
    {
      "epoch": 14.552891396332864,
      "grad_norm": 0.012443460524082184,
      "learning_rate": 2.575842696629214e-05,
      "loss": 0.0062,
      "step": 2590
    },
    {
      "epoch": 14.609308885754585,
      "grad_norm": 0.01716909371316433,
      "learning_rate": 2.566479400749064e-05,
      "loss": 0.0061,
      "step": 2600
    },
    {
      "epoch": 14.609308885754585,
      "eval_loss": 0.004450120963156223,
      "eval_runtime": 21.3781,
      "eval_samples_per_second": 2122.681,
      "eval_steps_per_second": 4.163,
      "step": 2600
    },
    {
      "epoch": 14.665726375176305,
      "grad_norm": 0.011664984747767448,
      "learning_rate": 2.557116104868914e-05,
      "loss": 0.0062,
      "step": 2610
    },
    {
      "epoch": 14.722143864598026,
      "grad_norm": 0.01901969127357006,
      "learning_rate": 2.5477528089887642e-05,
      "loss": 0.0062,
      "step": 2620
    },
    {
      "epoch": 14.778561354019747,
      "grad_norm": 0.013804202899336815,
      "learning_rate": 2.5383895131086144e-05,
      "loss": 0.0062,
      "step": 2630
    },
    {
      "epoch": 14.834978843441467,
      "grad_norm": 0.015494687482714653,
      "learning_rate": 2.5290262172284645e-05,
      "loss": 0.0061,
      "step": 2640
    },
    {
      "epoch": 14.891396332863188,
      "grad_norm": 0.015531687065958977,
      "learning_rate": 2.5196629213483146e-05,
      "loss": 0.0062,
      "step": 2650
    },
    {
      "epoch": 14.891396332863188,
      "eval_loss": 0.004473525565117598,
      "eval_runtime": 22.1601,
      "eval_samples_per_second": 2047.782,
      "eval_steps_per_second": 4.016,
      "step": 2650
    },
    {
      "epoch": 14.947813822284909,
      "grad_norm": 0.016707241535186768,
      "learning_rate": 2.5102996254681647e-05,
      "loss": 0.0062,
      "step": 2660
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.02067963033914566,
      "learning_rate": 2.5009363295880152e-05,
      "loss": 0.0062,
      "step": 2670
    },
    {
      "epoch": 15.05641748942172,
      "grad_norm": 0.014076313935220242,
      "learning_rate": 2.4915730337078653e-05,
      "loss": 0.0061,
      "step": 2680
    },
    {
      "epoch": 15.112834978843441,
      "grad_norm": 0.01148870401084423,
      "learning_rate": 2.4822097378277155e-05,
      "loss": 0.0062,
      "step": 2690
    },
    {
      "epoch": 15.169252468265162,
      "grad_norm": 0.012811440974473953,
      "learning_rate": 2.4728464419475656e-05,
      "loss": 0.0061,
      "step": 2700
    },
    {
      "epoch": 15.169252468265162,
      "eval_loss": 0.0044511789456009865,
      "eval_runtime": 22.4902,
      "eval_samples_per_second": 2017.719,
      "eval_steps_per_second": 3.957,
      "step": 2700
    },
    {
      "epoch": 15.225669957686883,
      "grad_norm": 0.01002934668213129,
      "learning_rate": 2.463483146067416e-05,
      "loss": 0.0061,
      "step": 2710
    },
    {
      "epoch": 15.282087447108603,
      "grad_norm": 0.014144031330943108,
      "learning_rate": 2.4541198501872662e-05,
      "loss": 0.0061,
      "step": 2720
    },
    {
      "epoch": 15.338504936530324,
      "grad_norm": 0.012539017014205456,
      "learning_rate": 2.4447565543071163e-05,
      "loss": 0.0062,
      "step": 2730
    },
    {
      "epoch": 15.394922425952045,
      "grad_norm": 0.011830342002213001,
      "learning_rate": 2.4353932584269664e-05,
      "loss": 0.0061,
      "step": 2740
    },
    {
      "epoch": 15.451339915373765,
      "grad_norm": 0.0117513258010149,
      "learning_rate": 2.4260299625468166e-05,
      "loss": 0.0062,
      "step": 2750
    },
    {
      "epoch": 15.451339915373765,
      "eval_loss": 0.004397871904075146,
      "eval_runtime": 22.2707,
      "eval_samples_per_second": 2037.609,
      "eval_steps_per_second": 3.996,
      "step": 2750
    },
    {
      "epoch": 15.507757404795486,
      "grad_norm": 0.01449385192245245,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 0.0061,
      "step": 2760
    },
    {
      "epoch": 15.564174894217206,
      "grad_norm": 0.013859495520591736,
      "learning_rate": 2.4073033707865168e-05,
      "loss": 0.0062,
      "step": 2770
    },
    {
      "epoch": 15.620592383638929,
      "grad_norm": 0.012350953184068203,
      "learning_rate": 2.3979400749063673e-05,
      "loss": 0.0061,
      "step": 2780
    },
    {
      "epoch": 15.67700987306065,
      "grad_norm": 0.008924426510930061,
      "learning_rate": 2.3885767790262174e-05,
      "loss": 0.0062,
      "step": 2790
    },
    {
      "epoch": 15.73342736248237,
      "grad_norm": 0.016703106462955475,
      "learning_rate": 2.3792134831460675e-05,
      "loss": 0.0061,
      "step": 2800
    },
    {
      "epoch": 15.73342736248237,
      "eval_loss": 0.004459841176867485,
      "eval_runtime": 22.9843,
      "eval_samples_per_second": 1974.35,
      "eval_steps_per_second": 3.872,
      "step": 2800
    },
    {
      "epoch": 15.78984485190409,
      "grad_norm": 0.013302809558808804,
      "learning_rate": 2.3698501872659176e-05,
      "loss": 0.0061,
      "step": 2810
    },
    {
      "epoch": 15.846262341325811,
      "grad_norm": 0.008049260824918747,
      "learning_rate": 2.3604868913857678e-05,
      "loss": 0.0062,
      "step": 2820
    },
    {
      "epoch": 15.902679830747532,
      "grad_norm": 0.018240701407194138,
      "learning_rate": 2.3511235955056182e-05,
      "loss": 0.0061,
      "step": 2830
    },
    {
      "epoch": 15.959097320169253,
      "grad_norm": 0.016539381816983223,
      "learning_rate": 2.3417602996254684e-05,
      "loss": 0.006,
      "step": 2840
    },
    {
      "epoch": 16.011283497884346,
      "grad_norm": 0.01514897495508194,
      "learning_rate": 2.3323970037453185e-05,
      "loss": 0.0062,
      "step": 2850
    },
    {
      "epoch": 16.011283497884346,
      "eval_loss": 0.004433844704180956,
      "eval_runtime": 22.999,
      "eval_samples_per_second": 1973.085,
      "eval_steps_per_second": 3.87,
      "step": 2850
    },
    {
      "epoch": 16.067700987306065,
      "grad_norm": 0.008559711277484894,
      "learning_rate": 2.3230337078651686e-05,
      "loss": 0.0061,
      "step": 2860
    },
    {
      "epoch": 16.124118476727787,
      "grad_norm": 0.010144149884581566,
      "learning_rate": 2.3136704119850187e-05,
      "loss": 0.0062,
      "step": 2870
    },
    {
      "epoch": 16.180535966149506,
      "grad_norm": 0.01064557209610939,
      "learning_rate": 2.3043071161048692e-05,
      "loss": 0.0061,
      "step": 2880
    },
    {
      "epoch": 16.23695345557123,
      "grad_norm": 0.013215875253081322,
      "learning_rate": 2.2949438202247193e-05,
      "loss": 0.0061,
      "step": 2890
    },
    {
      "epoch": 16.293370944992947,
      "grad_norm": 0.018766561523079872,
      "learning_rate": 2.2855805243445695e-05,
      "loss": 0.0061,
      "step": 2900
    },
    {
      "epoch": 16.293370944992947,
      "eval_loss": 0.004415940959006548,
      "eval_runtime": 22.0709,
      "eval_samples_per_second": 2056.056,
      "eval_steps_per_second": 4.032,
      "step": 2900
    },
    {
      "epoch": 16.34978843441467,
      "grad_norm": 0.012201396748423576,
      "learning_rate": 2.2762172284644196e-05,
      "loss": 0.0061,
      "step": 2910
    },
    {
      "epoch": 16.40620592383639,
      "grad_norm": 0.01646615006029606,
      "learning_rate": 2.2668539325842697e-05,
      "loss": 0.0061,
      "step": 2920
    },
    {
      "epoch": 16.46262341325811,
      "grad_norm": 0.013091132044792175,
      "learning_rate": 2.25749063670412e-05,
      "loss": 0.0061,
      "step": 2930
    },
    {
      "epoch": 16.51904090267983,
      "grad_norm": 0.014413057826459408,
      "learning_rate": 2.24812734082397e-05,
      "loss": 0.0061,
      "step": 2940
    },
    {
      "epoch": 16.575458392101552,
      "grad_norm": 0.0211685448884964,
      "learning_rate": 2.23876404494382e-05,
      "loss": 0.006,
      "step": 2950
    },
    {
      "epoch": 16.575458392101552,
      "eval_loss": 0.004402289167046547,
      "eval_runtime": 22.2024,
      "eval_samples_per_second": 2043.879,
      "eval_steps_per_second": 4.009,
      "step": 2950
    },
    {
      "epoch": 16.63187588152327,
      "grad_norm": 0.011243129149079323,
      "learning_rate": 2.2294007490636706e-05,
      "loss": 0.0061,
      "step": 2960
    },
    {
      "epoch": 16.688293370944994,
      "grad_norm": 0.0142606096342206,
      "learning_rate": 2.2200374531835207e-05,
      "loss": 0.0061,
      "step": 2970
    },
    {
      "epoch": 16.744710860366713,
      "grad_norm": 0.019466526806354523,
      "learning_rate": 2.2106741573033708e-05,
      "loss": 0.006,
      "step": 2980
    },
    {
      "epoch": 16.801128349788435,
      "grad_norm": 0.010457215830683708,
      "learning_rate": 2.2013108614232213e-05,
      "loss": 0.006,
      "step": 2990
    },
    {
      "epoch": 16.857545839210154,
      "grad_norm": 0.013498117215931416,
      "learning_rate": 2.1919475655430714e-05,
      "loss": 0.006,
      "step": 3000
    },
    {
      "epoch": 16.857545839210154,
      "eval_loss": 0.00440765917301178,
      "eval_runtime": 21.9695,
      "eval_samples_per_second": 2065.549,
      "eval_steps_per_second": 4.051,
      "step": 3000
    },
    {
      "epoch": 16.913963328631876,
      "grad_norm": 0.011999251320958138,
      "learning_rate": 2.1825842696629215e-05,
      "loss": 0.0062,
      "step": 3010
    },
    {
      "epoch": 16.970380818053595,
      "grad_norm": 0.014873035252094269,
      "learning_rate": 2.1732209737827716e-05,
      "loss": 0.0061,
      "step": 3020
    }
  ],
  "logging_steps": 10,
  "max_steps": 5340,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 512,
  "trial_name": null,
  "trial_params": null
}
