{
  "best_global_step": 3950,
  "best_metric": 0.004465759266167879,
  "best_model_checkpoint": null,
  "epoch": 25.0,
  "eval_steps": 50,
  "global_step": 4450,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.056417489421720736,
      "grad_norm": 2.8226778507232666,
      "learning_rate": 4.9915730337078655e-05,
      "loss": 0.2181,
      "step": 10
    },
    {
      "epoch": 0.11283497884344147,
      "grad_norm": 1.209165096282959,
      "learning_rate": 4.982209737827715e-05,
      "loss": 0.1196,
      "step": 20
    },
    {
      "epoch": 0.1692524682651622,
      "grad_norm": 0.5638683438301086,
      "learning_rate": 4.972846441947566e-05,
      "loss": 0.0715,
      "step": 30
    },
    {
      "epoch": 0.22566995768688294,
      "grad_norm": 0.1213342696428299,
      "learning_rate": 4.9634831460674155e-05,
      "loss": 0.0578,
      "step": 40
    },
    {
      "epoch": 0.2820874471086037,
      "grad_norm": 0.19870489835739136,
      "learning_rate": 4.954119850187266e-05,
      "loss": 0.0502,
      "step": 50
    },
    {
      "epoch": 0.2820874471086037,
      "eval_loss": 0.04031744599342346,
      "eval_runtime": 23.6489,
      "eval_samples_per_second": 1918.862,
      "eval_steps_per_second": 3.763,
      "step": 50
    },
    {
      "epoch": 0.3385049365303244,
      "grad_norm": 0.09901519119739532,
      "learning_rate": 4.9447565543071164e-05,
      "loss": 0.0449,
      "step": 60
    },
    {
      "epoch": 0.39492242595204513,
      "grad_norm": 0.07728242129087448,
      "learning_rate": 4.935393258426966e-05,
      "loss": 0.0409,
      "step": 70
    },
    {
      "epoch": 0.4513399153737659,
      "grad_norm": 0.06412651389837265,
      "learning_rate": 4.926029962546817e-05,
      "loss": 0.037,
      "step": 80
    },
    {
      "epoch": 0.5077574047954866,
      "grad_norm": 0.06219234690070152,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 0.0335,
      "step": 90
    },
    {
      "epoch": 0.5641748942172073,
      "grad_norm": 0.046373363584280014,
      "learning_rate": 4.9073033707865176e-05,
      "loss": 0.0315,
      "step": 100
    },
    {
      "epoch": 0.5641748942172073,
      "eval_loss": 0.025610292330384254,
      "eval_runtime": 21.9188,
      "eval_samples_per_second": 2070.327,
      "eval_steps_per_second": 4.06,
      "step": 100
    },
    {
      "epoch": 0.6205923836389281,
      "grad_norm": 0.04234747216105461,
      "learning_rate": 4.8979400749063674e-05,
      "loss": 0.0298,
      "step": 110
    },
    {
      "epoch": 0.6770098730606487,
      "grad_norm": 0.0371822863817215,
      "learning_rate": 4.888576779026218e-05,
      "loss": 0.0283,
      "step": 120
    },
    {
      "epoch": 0.7334273624823695,
      "grad_norm": 0.0384349524974823,
      "learning_rate": 4.8792134831460676e-05,
      "loss": 0.0271,
      "step": 130
    },
    {
      "epoch": 0.7898448519040903,
      "grad_norm": 0.04054601863026619,
      "learning_rate": 4.869850187265918e-05,
      "loss": 0.0263,
      "step": 140
    },
    {
      "epoch": 0.846262341325811,
      "grad_norm": 0.04509486258029938,
      "learning_rate": 4.860486891385768e-05,
      "loss": 0.0255,
      "step": 150
    },
    {
      "epoch": 0.846262341325811,
      "eval_loss": 0.020600037649273872,
      "eval_runtime": 21.6598,
      "eval_samples_per_second": 2095.08,
      "eval_steps_per_second": 4.109,
      "step": 150
    },
    {
      "epoch": 0.9026798307475318,
      "grad_norm": 0.04759328439831734,
      "learning_rate": 4.8511235955056184e-05,
      "loss": 0.0247,
      "step": 160
    },
    {
      "epoch": 0.9590973201692524,
      "grad_norm": 0.03175201267004013,
      "learning_rate": 4.841760299625469e-05,
      "loss": 0.0241,
      "step": 170
    },
    {
      "epoch": 1.0112834978843441,
      "grad_norm": 0.051870960742235184,
      "learning_rate": 4.8323970037453186e-05,
      "loss": 0.0238,
      "step": 180
    },
    {
      "epoch": 1.0677009873060648,
      "grad_norm": 0.03503371775150299,
      "learning_rate": 4.823033707865169e-05,
      "loss": 0.0234,
      "step": 190
    },
    {
      "epoch": 1.1241184767277856,
      "grad_norm": 0.027495699003338814,
      "learning_rate": 4.813670411985019e-05,
      "loss": 0.0233,
      "step": 200
    },
    {
      "epoch": 1.1241184767277856,
      "eval_loss": 0.01909657195210457,
      "eval_runtime": 21.0924,
      "eval_samples_per_second": 2151.436,
      "eval_steps_per_second": 4.22,
      "step": 200
    },
    {
      "epoch": 1.1805359661495063,
      "grad_norm": 0.03057163581252098,
      "learning_rate": 4.804307116104869e-05,
      "loss": 0.0228,
      "step": 210
    },
    {
      "epoch": 1.2369534555712272,
      "grad_norm": 0.02468409761786461,
      "learning_rate": 4.794943820224719e-05,
      "loss": 0.0226,
      "step": 220
    },
    {
      "epoch": 1.2933709449929478,
      "grad_norm": 0.02467079646885395,
      "learning_rate": 4.7855805243445696e-05,
      "loss": 0.0224,
      "step": 230
    },
    {
      "epoch": 1.3497884344146684,
      "grad_norm": 0.03088119626045227,
      "learning_rate": 4.7762172284644194e-05,
      "loss": 0.0221,
      "step": 240
    },
    {
      "epoch": 1.4062059238363893,
      "grad_norm": 0.019651155918836594,
      "learning_rate": 4.76685393258427e-05,
      "loss": 0.022,
      "step": 250
    },
    {
      "epoch": 1.4062059238363893,
      "eval_loss": 0.01831420511007309,
      "eval_runtime": 21.6441,
      "eval_samples_per_second": 2096.603,
      "eval_steps_per_second": 4.112,
      "step": 250
    },
    {
      "epoch": 1.46262341325811,
      "grad_norm": 0.023008180782198906,
      "learning_rate": 4.75749063670412e-05,
      "loss": 0.0217,
      "step": 260
    },
    {
      "epoch": 1.5190409026798308,
      "grad_norm": 0.021718010306358337,
      "learning_rate": 4.74812734082397e-05,
      "loss": 0.0216,
      "step": 270
    },
    {
      "epoch": 1.5754583921015515,
      "grad_norm": 0.014393829740583897,
      "learning_rate": 4.7387640449438205e-05,
      "loss": 0.0215,
      "step": 280
    },
    {
      "epoch": 1.6318758815232721,
      "grad_norm": 0.013527858071029186,
      "learning_rate": 4.72940074906367e-05,
      "loss": 0.0214,
      "step": 290
    },
    {
      "epoch": 1.688293370944993,
      "grad_norm": 0.01387154683470726,
      "learning_rate": 4.720037453183521e-05,
      "loss": 0.0214,
      "step": 300
    },
    {
      "epoch": 1.688293370944993,
      "eval_loss": 0.018158800899982452,
      "eval_runtime": 21.3576,
      "eval_samples_per_second": 2124.725,
      "eval_steps_per_second": 4.167,
      "step": 300
    },
    {
      "epoch": 1.7447108603667136,
      "grad_norm": 0.011288375593721867,
      "learning_rate": 4.7106741573033706e-05,
      "loss": 0.0212,
      "step": 310
    },
    {
      "epoch": 1.8011283497884345,
      "grad_norm": 0.01319305319339037,
      "learning_rate": 4.701310861423221e-05,
      "loss": 0.0211,
      "step": 320
    },
    {
      "epoch": 1.8575458392101551,
      "grad_norm": 0.012525029480457306,
      "learning_rate": 4.691947565543071e-05,
      "loss": 0.0212,
      "step": 330
    },
    {
      "epoch": 1.9139633286318758,
      "grad_norm": 0.011046286672353745,
      "learning_rate": 4.682584269662921e-05,
      "loss": 0.0211,
      "step": 340
    },
    {
      "epoch": 1.9703808180535967,
      "grad_norm": 0.014622800052165985,
      "learning_rate": 4.673220973782772e-05,
      "loss": 0.0211,
      "step": 350
    },
    {
      "epoch": 1.9703808180535967,
      "eval_loss": 0.018101191148161888,
      "eval_runtime": 21.4498,
      "eval_samples_per_second": 2115.59,
      "eval_steps_per_second": 4.149,
      "step": 350
    },
    {
      "epoch": 2.0225669957686883,
      "grad_norm": 0.010359898209571838,
      "learning_rate": 4.663857677902622e-05,
      "loss": 0.021,
      "step": 360
    },
    {
      "epoch": 2.078984485190409,
      "grad_norm": 0.012117511592805386,
      "learning_rate": 4.654494382022472e-05,
      "loss": 0.0211,
      "step": 370
    },
    {
      "epoch": 2.1354019746121295,
      "grad_norm": 0.014720268547534943,
      "learning_rate": 4.6451310861423225e-05,
      "loss": 0.0207,
      "step": 380
    },
    {
      "epoch": 2.1918194640338506,
      "grad_norm": 0.011104006320238113,
      "learning_rate": 4.635767790262173e-05,
      "loss": 0.021,
      "step": 390
    },
    {
      "epoch": 2.2482369534555713,
      "grad_norm": 0.014068876393139362,
      "learning_rate": 4.626404494382023e-05,
      "loss": 0.0211,
      "step": 400
    },
    {
      "epoch": 2.2482369534555713,
      "eval_loss": 0.01803065650165081,
      "eval_runtime": 20.782,
      "eval_samples_per_second": 2183.57,
      "eval_steps_per_second": 4.283,
      "step": 400
    },
    {
      "epoch": 2.304654442877292,
      "grad_norm": 0.011755379848182201,
      "learning_rate": 4.617041198501873e-05,
      "loss": 0.0208,
      "step": 410
    },
    {
      "epoch": 2.3610719322990126,
      "grad_norm": 0.017938319593667984,
      "learning_rate": 4.607677902621723e-05,
      "loss": 0.0208,
      "step": 420
    },
    {
      "epoch": 2.4174894217207337,
      "grad_norm": 0.01543812733143568,
      "learning_rate": 4.5983146067415735e-05,
      "loss": 0.0208,
      "step": 430
    },
    {
      "epoch": 2.4739069111424543,
      "grad_norm": 0.013844759203493595,
      "learning_rate": 4.588951310861423e-05,
      "loss": 0.0209,
      "step": 440
    },
    {
      "epoch": 2.530324400564175,
      "grad_norm": 0.013819986954331398,
      "learning_rate": 4.579588014981274e-05,
      "loss": 0.0208,
      "step": 450
    },
    {
      "epoch": 2.530324400564175,
      "eval_loss": 0.01797078363597393,
      "eval_runtime": 21.2161,
      "eval_samples_per_second": 2138.89,
      "eval_steps_per_second": 4.195,
      "step": 450
    },
    {
      "epoch": 2.5867418899858956,
      "grad_norm": 0.010998743586242199,
      "learning_rate": 4.5702247191011235e-05,
      "loss": 0.0209,
      "step": 460
    },
    {
      "epoch": 2.6431593794076162,
      "grad_norm": 0.012739434838294983,
      "learning_rate": 4.560861423220974e-05,
      "loss": 0.0207,
      "step": 470
    },
    {
      "epoch": 2.699576868829337,
      "grad_norm": 0.011922012083232403,
      "learning_rate": 4.5514981273408244e-05,
      "loss": 0.0207,
      "step": 480
    },
    {
      "epoch": 2.755994358251058,
      "grad_norm": 0.01351130846887827,
      "learning_rate": 4.542134831460674e-05,
      "loss": 0.0209,
      "step": 490
    },
    {
      "epoch": 2.8124118476727786,
      "grad_norm": 0.013792634010314941,
      "learning_rate": 4.532771535580525e-05,
      "loss": 0.0207,
      "step": 500
    },
    {
      "epoch": 2.8124118476727786,
      "eval_loss": 0.017748050391674042,
      "eval_runtime": 21.426,
      "eval_samples_per_second": 2117.94,
      "eval_steps_per_second": 4.154,
      "step": 500
    },
    {
      "epoch": 2.8688293370944993,
      "grad_norm": 0.015742579475045204,
      "learning_rate": 4.5234082397003745e-05,
      "loss": 0.0205,
      "step": 510
    },
    {
      "epoch": 2.92524682651622,
      "grad_norm": 0.012672766111791134,
      "learning_rate": 4.514044943820225e-05,
      "loss": 0.0205,
      "step": 520
    },
    {
      "epoch": 2.981664315937941,
      "grad_norm": 0.009227790869772434,
      "learning_rate": 4.504681647940075e-05,
      "loss": 0.0205,
      "step": 530
    },
    {
      "epoch": 3.0338504936530324,
      "grad_norm": 0.008967188186943531,
      "learning_rate": 4.495318352059925e-05,
      "loss": 0.0206,
      "step": 540
    },
    {
      "epoch": 3.090267983074753,
      "grad_norm": 0.01637054793536663,
      "learning_rate": 4.485955056179775e-05,
      "loss": 0.0204,
      "step": 550
    },
    {
      "epoch": 3.090267983074753,
      "eval_loss": 0.017664823681116104,
      "eval_runtime": 20.7143,
      "eval_samples_per_second": 2190.709,
      "eval_steps_per_second": 4.297,
      "step": 550
    },
    {
      "epoch": 3.1466854724964737,
      "grad_norm": 0.011402005329728127,
      "learning_rate": 4.4765917602996254e-05,
      "loss": 0.0205,
      "step": 560
    },
    {
      "epoch": 3.2031029619181948,
      "grad_norm": 0.008335843682289124,
      "learning_rate": 4.467228464419476e-05,
      "loss": 0.0204,
      "step": 570
    },
    {
      "epoch": 3.2595204513399154,
      "grad_norm": 0.00855204276740551,
      "learning_rate": 4.457865168539326e-05,
      "loss": 0.0204,
      "step": 580
    },
    {
      "epoch": 3.315937940761636,
      "grad_norm": 0.01903570257127285,
      "learning_rate": 4.448501872659177e-05,
      "loss": 0.0205,
      "step": 590
    },
    {
      "epoch": 3.3723554301833567,
      "grad_norm": 0.01739102229475975,
      "learning_rate": 4.4391385767790266e-05,
      "loss": 0.0203,
      "step": 600
    },
    {
      "epoch": 3.3723554301833567,
      "eval_loss": 0.017473872750997543,
      "eval_runtime": 21.4233,
      "eval_samples_per_second": 2118.21,
      "eval_steps_per_second": 4.154,
      "step": 600
    },
    {
      "epoch": 3.428772919605078,
      "grad_norm": 0.011910357512533665,
      "learning_rate": 4.429775280898877e-05,
      "loss": 0.0201,
      "step": 610
    },
    {
      "epoch": 3.4851904090267984,
      "grad_norm": 0.014080309309065342,
      "learning_rate": 4.420411985018727e-05,
      "loss": 0.0202,
      "step": 620
    },
    {
      "epoch": 3.541607898448519,
      "grad_norm": 0.009746885858476162,
      "learning_rate": 4.411048689138577e-05,
      "loss": 0.0202,
      "step": 630
    },
    {
      "epoch": 3.5980253878702397,
      "grad_norm": 0.013786179013550282,
      "learning_rate": 4.401685393258427e-05,
      "loss": 0.0199,
      "step": 640
    },
    {
      "epoch": 3.6544428772919604,
      "grad_norm": 0.008256128989160061,
      "learning_rate": 4.3923220973782776e-05,
      "loss": 0.0197,
      "step": 650
    },
    {
      "epoch": 3.6544428772919604,
      "eval_loss": 0.016782963648438454,
      "eval_runtime": 21.4694,
      "eval_samples_per_second": 2113.659,
      "eval_steps_per_second": 4.145,
      "step": 650
    },
    {
      "epoch": 3.710860366713681,
      "grad_norm": 0.01592063531279564,
      "learning_rate": 4.3829588014981274e-05,
      "loss": 0.0195,
      "step": 660
    },
    {
      "epoch": 3.767277856135402,
      "grad_norm": 0.015162060037255287,
      "learning_rate": 4.373595505617978e-05,
      "loss": 0.0192,
      "step": 670
    },
    {
      "epoch": 3.8236953455571228,
      "grad_norm": 0.01272554975003004,
      "learning_rate": 4.364232209737828e-05,
      "loss": 0.0189,
      "step": 680
    },
    {
      "epoch": 3.8801128349788434,
      "grad_norm": 0.025224890559911728,
      "learning_rate": 4.354868913857678e-05,
      "loss": 0.0182,
      "step": 690
    },
    {
      "epoch": 3.936530324400564,
      "grad_norm": 0.02731955796480179,
      "learning_rate": 4.3455056179775285e-05,
      "loss": 0.0179,
      "step": 700
    },
    {
      "epoch": 3.936530324400564,
      "eval_loss": 0.014934116974473,
      "eval_runtime": 21.1622,
      "eval_samples_per_second": 2144.341,
      "eval_steps_per_second": 4.206,
      "step": 700
    },
    {
      "epoch": 3.992947813822285,
      "grad_norm": 0.019290223717689514,
      "learning_rate": 4.336142322097378e-05,
      "loss": 0.0177,
      "step": 710
    },
    {
      "epoch": 4.0451339915373765,
      "grad_norm": 0.013041550293564796,
      "learning_rate": 4.326779026217229e-05,
      "loss": 0.0173,
      "step": 720
    },
    {
      "epoch": 4.101551480959097,
      "grad_norm": 0.02147728018462658,
      "learning_rate": 4.3174157303370786e-05,
      "loss": 0.017,
      "step": 730
    },
    {
      "epoch": 4.157968970380818,
      "grad_norm": 0.01564737968146801,
      "learning_rate": 4.308052434456929e-05,
      "loss": 0.017,
      "step": 740
    },
    {
      "epoch": 4.2143864598025385,
      "grad_norm": 0.024281373247504234,
      "learning_rate": 4.298689138576779e-05,
      "loss": 0.0168,
      "step": 750
    },
    {
      "epoch": 4.2143864598025385,
      "eval_loss": 0.01390921138226986,
      "eval_runtime": 21.0652,
      "eval_samples_per_second": 2154.221,
      "eval_steps_per_second": 4.225,
      "step": 750
    },
    {
      "epoch": 4.270803949224259,
      "grad_norm": 0.025319872424006462,
      "learning_rate": 4.289325842696629e-05,
      "loss": 0.0165,
      "step": 760
    },
    {
      "epoch": 4.327221438645981,
      "grad_norm": 0.0163596048951149,
      "learning_rate": 4.27996254681648e-05,
      "loss": 0.0164,
      "step": 770
    },
    {
      "epoch": 4.383638928067701,
      "grad_norm": 0.026364341378211975,
      "learning_rate": 4.2705992509363296e-05,
      "loss": 0.0162,
      "step": 780
    },
    {
      "epoch": 4.440056417489422,
      "grad_norm": 0.021059174090623856,
      "learning_rate": 4.26123595505618e-05,
      "loss": 0.016,
      "step": 790
    },
    {
      "epoch": 4.496473906911143,
      "grad_norm": 0.03676057234406471,
      "learning_rate": 4.25187265917603e-05,
      "loss": 0.0159,
      "step": 800
    },
    {
      "epoch": 4.496473906911143,
      "eval_loss": 0.013110579922795296,
      "eval_runtime": 21.3595,
      "eval_samples_per_second": 2124.532,
      "eval_steps_per_second": 4.167,
      "step": 800
    },
    {
      "epoch": 4.552891396332863,
      "grad_norm": 0.03211704641580582,
      "learning_rate": 4.24250936329588e-05,
      "loss": 0.0156,
      "step": 810
    },
    {
      "epoch": 4.609308885754584,
      "grad_norm": 0.012143390253186226,
      "learning_rate": 4.23314606741573e-05,
      "loss": 0.0155,
      "step": 820
    },
    {
      "epoch": 4.6657263751763045,
      "grad_norm": 0.01393264252692461,
      "learning_rate": 4.223782771535581e-05,
      "loss": 0.0153,
      "step": 830
    },
    {
      "epoch": 4.722143864598025,
      "grad_norm": 0.023836124688386917,
      "learning_rate": 4.214419475655431e-05,
      "loss": 0.0152,
      "step": 840
    },
    {
      "epoch": 4.778561354019746,
      "grad_norm": 0.012484372593462467,
      "learning_rate": 4.2050561797752815e-05,
      "loss": 0.0149,
      "step": 850
    },
    {
      "epoch": 4.778561354019746,
      "eval_loss": 0.012020391412079334,
      "eval_runtime": 21.6928,
      "eval_samples_per_second": 2091.89,
      "eval_steps_per_second": 4.103,
      "step": 850
    },
    {
      "epoch": 4.834978843441467,
      "grad_norm": 0.01337828766554594,
      "learning_rate": 4.195692883895131e-05,
      "loss": 0.015,
      "step": 860
    },
    {
      "epoch": 4.891396332863188,
      "grad_norm": 0.01652449741959572,
      "learning_rate": 4.186329588014982e-05,
      "loss": 0.0147,
      "step": 870
    },
    {
      "epoch": 4.947813822284909,
      "grad_norm": 0.017173754051327705,
      "learning_rate": 4.1769662921348315e-05,
      "loss": 0.0145,
      "step": 880
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.028819182887673378,
      "learning_rate": 4.167602996254682e-05,
      "loss": 0.0145,
      "step": 890
    },
    {
      "epoch": 5.056417489421721,
      "grad_norm": 0.033327795565128326,
      "learning_rate": 4.1582397003745324e-05,
      "loss": 0.0143,
      "step": 900
    },
    {
      "epoch": 5.056417489421721,
      "eval_loss": 0.011242726817727089,
      "eval_runtime": 21.0378,
      "eval_samples_per_second": 2157.017,
      "eval_steps_per_second": 4.23,
      "step": 900
    },
    {
      "epoch": 5.112834978843441,
      "grad_norm": 0.03421127796173096,
      "learning_rate": 4.148876404494382e-05,
      "loss": 0.0143,
      "step": 910
    },
    {
      "epoch": 5.169252468265162,
      "grad_norm": 0.01566017046570778,
      "learning_rate": 4.139513108614233e-05,
      "loss": 0.014,
      "step": 920
    },
    {
      "epoch": 5.225669957686883,
      "grad_norm": 0.02124771662056446,
      "learning_rate": 4.1301498127340825e-05,
      "loss": 0.014,
      "step": 930
    },
    {
      "epoch": 5.282087447108603,
      "grad_norm": 0.022788673639297485,
      "learning_rate": 4.120786516853933e-05,
      "loss": 0.0138,
      "step": 940
    },
    {
      "epoch": 5.338504936530325,
      "grad_norm": 0.012872832827270031,
      "learning_rate": 4.111423220973783e-05,
      "loss": 0.0136,
      "step": 950
    },
    {
      "epoch": 5.338504936530325,
      "eval_loss": 0.010633128695189953,
      "eval_runtime": 21.6437,
      "eval_samples_per_second": 2096.639,
      "eval_steps_per_second": 4.112,
      "step": 950
    },
    {
      "epoch": 5.394922425952045,
      "grad_norm": 0.023578355088829994,
      "learning_rate": 4.102059925093633e-05,
      "loss": 0.0134,
      "step": 960
    },
    {
      "epoch": 5.451339915373766,
      "grad_norm": 0.0337824821472168,
      "learning_rate": 4.092696629213483e-05,
      "loss": 0.0135,
      "step": 970
    },
    {
      "epoch": 5.507757404795487,
      "grad_norm": 0.012819930911064148,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 0.0132,
      "step": 980
    },
    {
      "epoch": 5.564174894217207,
      "grad_norm": 0.027279941365122795,
      "learning_rate": 4.073970037453184e-05,
      "loss": 0.0131,
      "step": 990
    },
    {
      "epoch": 5.620592383638928,
      "grad_norm": 0.0199260376393795,
      "learning_rate": 4.064606741573034e-05,
      "loss": 0.0131,
      "step": 1000
    },
    {
      "epoch": 5.620592383638928,
      "eval_loss": 0.010063528083264828,
      "eval_runtime": 21.5647,
      "eval_samples_per_second": 2104.321,
      "eval_steps_per_second": 4.127,
      "step": 1000
    },
    {
      "epoch": 5.677009873060649,
      "grad_norm": 0.019224615767598152,
      "learning_rate": 4.055243445692884e-05,
      "loss": 0.013,
      "step": 1010
    },
    {
      "epoch": 5.733427362482369,
      "grad_norm": 0.014682496897876263,
      "learning_rate": 4.045880149812734e-05,
      "loss": 0.0128,
      "step": 1020
    },
    {
      "epoch": 5.78984485190409,
      "grad_norm": 0.013309251517057419,
      "learning_rate": 4.0365168539325844e-05,
      "loss": 0.0128,
      "step": 1030
    },
    {
      "epoch": 5.8462623413258115,
      "grad_norm": 0.015418664552271366,
      "learning_rate": 4.027153558052434e-05,
      "loss": 0.0127,
      "step": 1040
    },
    {
      "epoch": 5.902679830747532,
      "grad_norm": 0.02080446109175682,
      "learning_rate": 4.0177902621722846e-05,
      "loss": 0.0126,
      "step": 1050
    },
    {
      "epoch": 5.902679830747532,
      "eval_loss": 0.009516541846096516,
      "eval_runtime": 21.3105,
      "eval_samples_per_second": 2129.416,
      "eval_steps_per_second": 4.176,
      "step": 1050
    },
    {
      "epoch": 5.959097320169253,
      "grad_norm": 0.01861303485929966,
      "learning_rate": 4.0084269662921344e-05,
      "loss": 0.0126,
      "step": 1060
    },
    {
      "epoch": 6.011283497884344,
      "grad_norm": 0.014820295386016369,
      "learning_rate": 3.9990636704119856e-05,
      "loss": 0.0124,
      "step": 1070
    },
    {
      "epoch": 6.067700987306065,
      "grad_norm": 0.020576126873493195,
      "learning_rate": 3.9897003745318354e-05,
      "loss": 0.0123,
      "step": 1080
    },
    {
      "epoch": 6.124118476727785,
      "grad_norm": 0.015636414289474487,
      "learning_rate": 3.980337078651686e-05,
      "loss": 0.0123,
      "step": 1090
    },
    {
      "epoch": 6.180535966149506,
      "grad_norm": 0.01870284043252468,
      "learning_rate": 3.970973782771536e-05,
      "loss": 0.0121,
      "step": 1100
    },
    {
      "epoch": 6.180535966149506,
      "eval_loss": 0.009136312641203403,
      "eval_runtime": 20.9192,
      "eval_samples_per_second": 2169.25,
      "eval_steps_per_second": 4.254,
      "step": 1100
    },
    {
      "epoch": 6.236953455571227,
      "grad_norm": 0.020112331956624985,
      "learning_rate": 3.961610486891386e-05,
      "loss": 0.012,
      "step": 1110
    },
    {
      "epoch": 6.293370944992947,
      "grad_norm": 0.010807175189256668,
      "learning_rate": 3.9522471910112365e-05,
      "loss": 0.012,
      "step": 1120
    },
    {
      "epoch": 6.349788434414669,
      "grad_norm": 0.0185640100389719,
      "learning_rate": 3.942883895131086e-05,
      "loss": 0.0118,
      "step": 1130
    },
    {
      "epoch": 6.4062059238363895,
      "grad_norm": 0.0261694323271513,
      "learning_rate": 3.933520599250937e-05,
      "loss": 0.0118,
      "step": 1140
    },
    {
      "epoch": 6.46262341325811,
      "grad_norm": 0.024219177663326263,
      "learning_rate": 3.9241573033707866e-05,
      "loss": 0.0117,
      "step": 1150
    },
    {
      "epoch": 6.46262341325811,
      "eval_loss": 0.008718757890164852,
      "eval_runtime": 21.3135,
      "eval_samples_per_second": 2129.119,
      "eval_steps_per_second": 4.176,
      "step": 1150
    },
    {
      "epoch": 6.519040902679831,
      "grad_norm": 0.01766854338347912,
      "learning_rate": 3.914794007490637e-05,
      "loss": 0.0117,
      "step": 1160
    },
    {
      "epoch": 6.5754583921015515,
      "grad_norm": 0.011028477922081947,
      "learning_rate": 3.905430711610487e-05,
      "loss": 0.0116,
      "step": 1170
    },
    {
      "epoch": 6.631875881523272,
      "grad_norm": 0.018292684108018875,
      "learning_rate": 3.896067415730337e-05,
      "loss": 0.0116,
      "step": 1180
    },
    {
      "epoch": 6.688293370944993,
      "grad_norm": 0.01763453520834446,
      "learning_rate": 3.886704119850188e-05,
      "loss": 0.0115,
      "step": 1190
    },
    {
      "epoch": 6.744710860366713,
      "grad_norm": 0.016145994886755943,
      "learning_rate": 3.8773408239700376e-05,
      "loss": 0.0114,
      "step": 1200
    },
    {
      "epoch": 6.744710860366713,
      "eval_loss": 0.00822613574564457,
      "eval_runtime": 21.697,
      "eval_samples_per_second": 2091.485,
      "eval_steps_per_second": 4.102,
      "step": 1200
    },
    {
      "epoch": 6.801128349788434,
      "grad_norm": 0.014854053035378456,
      "learning_rate": 3.867977528089888e-05,
      "loss": 0.0113,
      "step": 1210
    },
    {
      "epoch": 6.857545839210156,
      "grad_norm": 0.01181220542639494,
      "learning_rate": 3.858614232209738e-05,
      "loss": 0.0113,
      "step": 1220
    },
    {
      "epoch": 6.913963328631876,
      "grad_norm": 0.014905049465596676,
      "learning_rate": 3.849250936329588e-05,
      "loss": 0.0112,
      "step": 1230
    },
    {
      "epoch": 6.970380818053597,
      "grad_norm": 0.011309480294585228,
      "learning_rate": 3.839887640449438e-05,
      "loss": 0.011,
      "step": 1240
    },
    {
      "epoch": 7.022566995768688,
      "grad_norm": 0.016063900664448738,
      "learning_rate": 3.8305243445692885e-05,
      "loss": 0.0111,
      "step": 1250
    },
    {
      "epoch": 7.022566995768688,
      "eval_loss": 0.007866994477808475,
      "eval_runtime": 21.0563,
      "eval_samples_per_second": 2155.132,
      "eval_steps_per_second": 4.227,
      "step": 1250
    },
    {
      "epoch": 7.078984485190409,
      "grad_norm": 0.01993972808122635,
      "learning_rate": 3.821161048689138e-05,
      "loss": 0.0109,
      "step": 1260
    },
    {
      "epoch": 7.1354019746121295,
      "grad_norm": 0.016783006489276886,
      "learning_rate": 3.811797752808989e-05,
      "loss": 0.0108,
      "step": 1270
    },
    {
      "epoch": 7.19181946403385,
      "grad_norm": 0.017008181661367416,
      "learning_rate": 3.802434456928839e-05,
      "loss": 0.0108,
      "step": 1280
    },
    {
      "epoch": 7.248236953455571,
      "grad_norm": 0.013784763403236866,
      "learning_rate": 3.793071161048689e-05,
      "loss": 0.0106,
      "step": 1290
    },
    {
      "epoch": 7.304654442877292,
      "grad_norm": 0.01463242620229721,
      "learning_rate": 3.7837078651685395e-05,
      "loss": 0.0106,
      "step": 1300
    },
    {
      "epoch": 7.304654442877292,
      "eval_loss": 0.007446816191077232,
      "eval_runtime": 21.4432,
      "eval_samples_per_second": 2116.242,
      "eval_steps_per_second": 4.15,
      "step": 1300
    },
    {
      "epoch": 7.361071932299013,
      "grad_norm": 0.011642802506685257,
      "learning_rate": 3.774344569288389e-05,
      "loss": 0.0105,
      "step": 1310
    },
    {
      "epoch": 7.417489421720734,
      "grad_norm": 0.01684819534420967,
      "learning_rate": 3.7649812734082404e-05,
      "loss": 0.0105,
      "step": 1320
    },
    {
      "epoch": 7.473906911142454,
      "grad_norm": 0.014799302443861961,
      "learning_rate": 3.75561797752809e-05,
      "loss": 0.0105,
      "step": 1330
    },
    {
      "epoch": 7.530324400564175,
      "grad_norm": 0.015210654586553574,
      "learning_rate": 3.746254681647941e-05,
      "loss": 0.0104,
      "step": 1340
    },
    {
      "epoch": 7.586741889985896,
      "grad_norm": 0.012944445013999939,
      "learning_rate": 3.7368913857677905e-05,
      "loss": 0.0105,
      "step": 1350
    },
    {
      "epoch": 7.586741889985896,
      "eval_loss": 0.00713811069726944,
      "eval_runtime": 21.751,
      "eval_samples_per_second": 2086.297,
      "eval_steps_per_second": 4.092,
      "step": 1350
    },
    {
      "epoch": 7.643159379407616,
      "grad_norm": 0.026953203603625298,
      "learning_rate": 3.727528089887641e-05,
      "loss": 0.0102,
      "step": 1360
    },
    {
      "epoch": 7.699576868829337,
      "grad_norm": 0.018733663484454155,
      "learning_rate": 3.718164794007491e-05,
      "loss": 0.0103,
      "step": 1370
    },
    {
      "epoch": 7.7559943582510575,
      "grad_norm": 0.012583764269948006,
      "learning_rate": 3.708801498127341e-05,
      "loss": 0.0103,
      "step": 1380
    },
    {
      "epoch": 7.812411847672778,
      "grad_norm": 0.013040450401604176,
      "learning_rate": 3.699438202247191e-05,
      "loss": 0.0101,
      "step": 1390
    },
    {
      "epoch": 7.8688293370945,
      "grad_norm": 0.014338391833007336,
      "learning_rate": 3.6900749063670414e-05,
      "loss": 0.0101,
      "step": 1400
    },
    {
      "epoch": 7.8688293370945,
      "eval_loss": 0.006938144098967314,
      "eval_runtime": 20.9716,
      "eval_samples_per_second": 2163.834,
      "eval_steps_per_second": 4.244,
      "step": 1400
    },
    {
      "epoch": 7.92524682651622,
      "grad_norm": 0.014521954581141472,
      "learning_rate": 3.680711610486892e-05,
      "loss": 0.0101,
      "step": 1410
    },
    {
      "epoch": 7.981664315937941,
      "grad_norm": 0.0207216776907444,
      "learning_rate": 3.671348314606742e-05,
      "loss": 0.01,
      "step": 1420
    },
    {
      "epoch": 8.033850493653032,
      "grad_norm": 0.021321555599570274,
      "learning_rate": 3.661985018726592e-05,
      "loss": 0.01,
      "step": 1430
    },
    {
      "epoch": 8.090267983074753,
      "grad_norm": 0.011124219745397568,
      "learning_rate": 3.652621722846442e-05,
      "loss": 0.0098,
      "step": 1440
    },
    {
      "epoch": 8.146685472496474,
      "grad_norm": 0.017888395115733147,
      "learning_rate": 3.6432584269662924e-05,
      "loss": 0.0099,
      "step": 1450
    },
    {
      "epoch": 8.146685472496474,
      "eval_loss": 0.006716439966112375,
      "eval_runtime": 20.9926,
      "eval_samples_per_second": 2161.666,
      "eval_steps_per_second": 4.24,
      "step": 1450
    },
    {
      "epoch": 8.203102961918194,
      "grad_norm": 0.017253702506422997,
      "learning_rate": 3.633895131086142e-05,
      "loss": 0.0099,
      "step": 1460
    },
    {
      "epoch": 8.259520451339915,
      "grad_norm": 0.010935361497104168,
      "learning_rate": 3.6245318352059926e-05,
      "loss": 0.0099,
      "step": 1470
    },
    {
      "epoch": 8.315937940761636,
      "grad_norm": 0.013539034873247147,
      "learning_rate": 3.6151685393258424e-05,
      "loss": 0.0098,
      "step": 1480
    },
    {
      "epoch": 8.372355430183356,
      "grad_norm": 0.016863016411662102,
      "learning_rate": 3.605805243445693e-05,
      "loss": 0.0098,
      "step": 1490
    },
    {
      "epoch": 8.428772919605077,
      "grad_norm": 0.010420911945402622,
      "learning_rate": 3.5964419475655434e-05,
      "loss": 0.0097,
      "step": 1500
    },
    {
      "epoch": 8.428772919605077,
      "eval_loss": 0.006481867749243975,
      "eval_runtime": 21.2685,
      "eval_samples_per_second": 2133.63,
      "eval_steps_per_second": 4.185,
      "step": 1500
    },
    {
      "epoch": 8.485190409026798,
      "grad_norm": 0.013238481245934963,
      "learning_rate": 3.587078651685393e-05,
      "loss": 0.0096,
      "step": 1510
    },
    {
      "epoch": 8.541607898448518,
      "grad_norm": 0.018916720524430275,
      "learning_rate": 3.5777153558052436e-05,
      "loss": 0.0096,
      "step": 1520
    },
    {
      "epoch": 8.59802538787024,
      "grad_norm": 0.02011352777481079,
      "learning_rate": 3.5683520599250934e-05,
      "loss": 0.0095,
      "step": 1530
    },
    {
      "epoch": 8.654442877291961,
      "grad_norm": 0.022759512066841125,
      "learning_rate": 3.558988764044944e-05,
      "loss": 0.0094,
      "step": 1540
    },
    {
      "epoch": 8.710860366713682,
      "grad_norm": 0.015640275552868843,
      "learning_rate": 3.5496254681647937e-05,
      "loss": 0.0094,
      "step": 1550
    },
    {
      "epoch": 8.710860366713682,
      "eval_loss": 0.006289098411798477,
      "eval_runtime": 21.3996,
      "eval_samples_per_second": 2120.556,
      "eval_steps_per_second": 4.159,
      "step": 1550
    },
    {
      "epoch": 8.767277856135403,
      "grad_norm": 0.013710898347198963,
      "learning_rate": 3.540262172284645e-05,
      "loss": 0.0094,
      "step": 1560
    },
    {
      "epoch": 8.823695345557123,
      "grad_norm": 0.011308038607239723,
      "learning_rate": 3.5308988764044946e-05,
      "loss": 0.0094,
      "step": 1570
    },
    {
      "epoch": 8.880112834978844,
      "grad_norm": 0.014524743892252445,
      "learning_rate": 3.521535580524345e-05,
      "loss": 0.0094,
      "step": 1580
    },
    {
      "epoch": 8.936530324400564,
      "grad_norm": 0.014817556366324425,
      "learning_rate": 3.512172284644195e-05,
      "loss": 0.0092,
      "step": 1590
    },
    {
      "epoch": 8.992947813822285,
      "grad_norm": 0.013611319474875927,
      "learning_rate": 3.502808988764045e-05,
      "loss": 0.0092,
      "step": 1600
    },
    {
      "epoch": 8.992947813822285,
      "eval_loss": 0.006166568957269192,
      "eval_runtime": 20.8011,
      "eval_samples_per_second": 2181.57,
      "eval_steps_per_second": 4.279,
      "step": 1600
    },
    {
      "epoch": 9.045133991537377,
      "grad_norm": 0.019989555701613426,
      "learning_rate": 3.493445692883896e-05,
      "loss": 0.0092,
      "step": 1610
    },
    {
      "epoch": 9.101551480959097,
      "grad_norm": 0.01753050461411476,
      "learning_rate": 3.4840823970037456e-05,
      "loss": 0.0091,
      "step": 1620
    },
    {
      "epoch": 9.157968970380818,
      "grad_norm": 0.01680154539644718,
      "learning_rate": 3.474719101123596e-05,
      "loss": 0.0091,
      "step": 1630
    },
    {
      "epoch": 9.214386459802538,
      "grad_norm": 0.01673831418156624,
      "learning_rate": 3.465355805243446e-05,
      "loss": 0.009,
      "step": 1640
    },
    {
      "epoch": 9.270803949224259,
      "grad_norm": 0.020467765629291534,
      "learning_rate": 3.455992509363296e-05,
      "loss": 0.009,
      "step": 1650
    },
    {
      "epoch": 9.270803949224259,
      "eval_loss": 0.005989618133753538,
      "eval_runtime": 21.2647,
      "eval_samples_per_second": 2134.01,
      "eval_steps_per_second": 4.185,
      "step": 1650
    },
    {
      "epoch": 9.32722143864598,
      "grad_norm": 0.012707558460533619,
      "learning_rate": 3.446629213483146e-05,
      "loss": 0.0089,
      "step": 1660
    },
    {
      "epoch": 9.3836389280677,
      "grad_norm": 0.015284137800335884,
      "learning_rate": 3.4372659176029965e-05,
      "loss": 0.0089,
      "step": 1670
    },
    {
      "epoch": 9.440056417489421,
      "grad_norm": 0.01512814685702324,
      "learning_rate": 3.427902621722846e-05,
      "loss": 0.0089,
      "step": 1680
    },
    {
      "epoch": 9.496473906911142,
      "grad_norm": 0.018646743148565292,
      "learning_rate": 3.418539325842697e-05,
      "loss": 0.0088,
      "step": 1690
    },
    {
      "epoch": 9.552891396332864,
      "grad_norm": 0.010499261319637299,
      "learning_rate": 3.409176029962547e-05,
      "loss": 0.0089,
      "step": 1700
    },
    {
      "epoch": 9.552891396332864,
      "eval_loss": 0.005726999137550592,
      "eval_runtime": 21.2698,
      "eval_samples_per_second": 2133.498,
      "eval_steps_per_second": 4.184,
      "step": 1700
    },
    {
      "epoch": 9.609308885754585,
      "grad_norm": 0.012870404869318008,
      "learning_rate": 3.399812734082397e-05,
      "loss": 0.0087,
      "step": 1710
    },
    {
      "epoch": 9.665726375176305,
      "grad_norm": 0.01677880808711052,
      "learning_rate": 3.3904494382022475e-05,
      "loss": 0.0088,
      "step": 1720
    },
    {
      "epoch": 9.722143864598026,
      "grad_norm": 0.013322225771844387,
      "learning_rate": 3.381086142322097e-05,
      "loss": 0.0085,
      "step": 1730
    },
    {
      "epoch": 9.778561354019747,
      "grad_norm": 0.013315281830728054,
      "learning_rate": 3.371722846441948e-05,
      "loss": 0.0085,
      "step": 1740
    },
    {
      "epoch": 9.834978843441467,
      "grad_norm": 0.013107958249747753,
      "learning_rate": 3.3623595505617975e-05,
      "loss": 0.0085,
      "step": 1750
    },
    {
      "epoch": 9.834978843441467,
      "eval_loss": 0.005591432563960552,
      "eval_runtime": 21.3643,
      "eval_samples_per_second": 2124.057,
      "eval_steps_per_second": 4.166,
      "step": 1750
    },
    {
      "epoch": 9.891396332863188,
      "grad_norm": 0.01742924563586712,
      "learning_rate": 3.352996254681648e-05,
      "loss": 0.0086,
      "step": 1760
    },
    {
      "epoch": 9.947813822284909,
      "grad_norm": 0.017030825838446617,
      "learning_rate": 3.343632958801498e-05,
      "loss": 0.0086,
      "step": 1770
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.018793532624840736,
      "learning_rate": 3.334269662921348e-05,
      "loss": 0.0084,
      "step": 1780
    },
    {
      "epoch": 10.05641748942172,
      "grad_norm": 0.0197326447814703,
      "learning_rate": 3.324906367041199e-05,
      "loss": 0.0084,
      "step": 1790
    },
    {
      "epoch": 10.112834978843441,
      "grad_norm": 0.021325642243027687,
      "learning_rate": 3.315543071161049e-05,
      "loss": 0.0083,
      "step": 1800
    },
    {
      "epoch": 10.112834978843441,
      "eval_loss": 0.005468584131449461,
      "eval_runtime": 20.6158,
      "eval_samples_per_second": 2201.18,
      "eval_steps_per_second": 4.317,
      "step": 1800
    },
    {
      "epoch": 10.169252468265162,
      "grad_norm": 0.015781693160533905,
      "learning_rate": 3.306179775280899e-05,
      "loss": 0.0084,
      "step": 1810
    },
    {
      "epoch": 10.225669957686883,
      "grad_norm": 0.017068689689040184,
      "learning_rate": 3.2968164794007494e-05,
      "loss": 0.0083,
      "step": 1820
    },
    {
      "epoch": 10.282087447108603,
      "grad_norm": 0.017094263806939125,
      "learning_rate": 3.2874531835206e-05,
      "loss": 0.0084,
      "step": 1830
    },
    {
      "epoch": 10.338504936530324,
      "grad_norm": 0.021933184936642647,
      "learning_rate": 3.27808988764045e-05,
      "loss": 0.0082,
      "step": 1840
    },
    {
      "epoch": 10.394922425952045,
      "grad_norm": 0.013278918340802193,
      "learning_rate": 3.2687265917603e-05,
      "loss": 0.0082,
      "step": 1850
    },
    {
      "epoch": 10.394922425952045,
      "eval_loss": 0.005376344546675682,
      "eval_runtime": 21.0561,
      "eval_samples_per_second": 2155.149,
      "eval_steps_per_second": 4.227,
      "step": 1850
    },
    {
      "epoch": 10.451339915373765,
      "grad_norm": 0.014526302926242352,
      "learning_rate": 3.25936329588015e-05,
      "loss": 0.0082,
      "step": 1860
    },
    {
      "epoch": 10.507757404795486,
      "grad_norm": 0.011260205879807472,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.0082,
      "step": 1870
    },
    {
      "epoch": 10.564174894217206,
      "grad_norm": 0.012902761809527874,
      "learning_rate": 3.24063670411985e-05,
      "loss": 0.0081,
      "step": 1880
    },
    {
      "epoch": 10.620592383638929,
      "grad_norm": 0.018237007781863213,
      "learning_rate": 3.2312734082397006e-05,
      "loss": 0.0081,
      "step": 1890
    },
    {
      "epoch": 10.67700987306065,
      "grad_norm": 0.012371126562356949,
      "learning_rate": 3.2219101123595504e-05,
      "loss": 0.008,
      "step": 1900
    },
    {
      "epoch": 10.67700987306065,
      "eval_loss": 0.00527042243629694,
      "eval_runtime": 21.2043,
      "eval_samples_per_second": 2140.087,
      "eval_steps_per_second": 4.197,
      "step": 1900
    },
    {
      "epoch": 10.73342736248237,
      "grad_norm": 0.01495907362550497,
      "learning_rate": 3.212546816479401e-05,
      "loss": 0.0081,
      "step": 1910
    },
    {
      "epoch": 10.78984485190409,
      "grad_norm": 0.015228225849568844,
      "learning_rate": 3.2031835205992514e-05,
      "loss": 0.0081,
      "step": 1920
    },
    {
      "epoch": 10.846262341325811,
      "grad_norm": 0.01547736581414938,
      "learning_rate": 3.193820224719101e-05,
      "loss": 0.008,
      "step": 1930
    },
    {
      "epoch": 10.902679830747532,
      "grad_norm": 0.013705525547266006,
      "learning_rate": 3.1844569288389516e-05,
      "loss": 0.008,
      "step": 1940
    },
    {
      "epoch": 10.959097320169253,
      "grad_norm": 0.01475498266518116,
      "learning_rate": 3.1750936329588014e-05,
      "loss": 0.008,
      "step": 1950
    },
    {
      "epoch": 10.959097320169253,
      "eval_loss": 0.005166026763617992,
      "eval_runtime": 21.5133,
      "eval_samples_per_second": 2109.351,
      "eval_steps_per_second": 4.137,
      "step": 1950
    },
    {
      "epoch": 11.011283497884344,
      "grad_norm": 0.011986837722361088,
      "learning_rate": 3.165730337078652e-05,
      "loss": 0.0079,
      "step": 1960
    },
    {
      "epoch": 11.067700987306065,
      "grad_norm": 0.01642591506242752,
      "learning_rate": 3.1563670411985017e-05,
      "loss": 0.008,
      "step": 1970
    },
    {
      "epoch": 11.124118476727785,
      "grad_norm": 0.01291784830391407,
      "learning_rate": 3.147003745318352e-05,
      "loss": 0.0079,
      "step": 1980
    },
    {
      "epoch": 11.180535966149506,
      "grad_norm": 0.010310392826795578,
      "learning_rate": 3.137640449438202e-05,
      "loss": 0.0079,
      "step": 1990
    },
    {
      "epoch": 11.236953455571227,
      "grad_norm": 0.010553439147770405,
      "learning_rate": 3.1282771535580524e-05,
      "loss": 0.0078,
      "step": 2000
    },
    {
      "epoch": 11.236953455571227,
      "eval_loss": 0.005058235488831997,
      "eval_runtime": 20.9359,
      "eval_samples_per_second": 2167.526,
      "eval_steps_per_second": 4.251,
      "step": 2000
    },
    {
      "epoch": 11.293370944992947,
      "grad_norm": 0.013762963935732841,
      "learning_rate": 3.118913857677903e-05,
      "loss": 0.0078,
      "step": 2010
    },
    {
      "epoch": 11.349788434414668,
      "grad_norm": 0.013676494359970093,
      "learning_rate": 3.1095505617977526e-05,
      "loss": 0.0079,
      "step": 2020
    },
    {
      "epoch": 11.406205923836389,
      "grad_norm": 0.017697954550385475,
      "learning_rate": 3.100187265917603e-05,
      "loss": 0.0077,
      "step": 2030
    },
    {
      "epoch": 11.46262341325811,
      "grad_norm": 0.012541944161057472,
      "learning_rate": 3.0908239700374535e-05,
      "loss": 0.0077,
      "step": 2040
    },
    {
      "epoch": 11.51904090267983,
      "grad_norm": 0.012361111119389534,
      "learning_rate": 3.081460674157304e-05,
      "loss": 0.0077,
      "step": 2050
    },
    {
      "epoch": 11.51904090267983,
      "eval_loss": 0.005026007536798716,
      "eval_runtime": 21.4796,
      "eval_samples_per_second": 2112.655,
      "eval_steps_per_second": 4.143,
      "step": 2050
    },
    {
      "epoch": 11.575458392101552,
      "grad_norm": 0.013081750832498074,
      "learning_rate": 3.072097378277154e-05,
      "loss": 0.0076,
      "step": 2060
    },
    {
      "epoch": 11.631875881523273,
      "grad_norm": 0.011167504824697971,
      "learning_rate": 3.062734082397004e-05,
      "loss": 0.0077,
      "step": 2070
    },
    {
      "epoch": 11.688293370944994,
      "grad_norm": 0.012245937250554562,
      "learning_rate": 3.053370786516854e-05,
      "loss": 0.0076,
      "step": 2080
    },
    {
      "epoch": 11.744710860366714,
      "grad_norm": 0.02403399348258972,
      "learning_rate": 3.0440074906367045e-05,
      "loss": 0.0077,
      "step": 2090
    },
    {
      "epoch": 11.801128349788435,
      "grad_norm": 0.015669122338294983,
      "learning_rate": 3.0346441947565546e-05,
      "loss": 0.0076,
      "step": 2100
    },
    {
      "epoch": 11.801128349788435,
      "eval_loss": 0.004952141549438238,
      "eval_runtime": 21.819,
      "eval_samples_per_second": 2079.794,
      "eval_steps_per_second": 4.079,
      "step": 2100
    },
    {
      "epoch": 11.857545839210156,
      "grad_norm": 0.0180678628385067,
      "learning_rate": 3.0252808988764048e-05,
      "loss": 0.0075,
      "step": 2110
    },
    {
      "epoch": 11.913963328631876,
      "grad_norm": 0.019567083567380905,
      "learning_rate": 3.015917602996255e-05,
      "loss": 0.0077,
      "step": 2120
    },
    {
      "epoch": 11.970380818053597,
      "grad_norm": 0.012037812732160091,
      "learning_rate": 3.006554307116105e-05,
      "loss": 0.0076,
      "step": 2130
    },
    {
      "epoch": 12.022566995768688,
      "grad_norm": 0.02445017732679844,
      "learning_rate": 2.997191011235955e-05,
      "loss": 0.0076,
      "step": 2140
    },
    {
      "epoch": 12.078984485190409,
      "grad_norm": 0.013213793747127056,
      "learning_rate": 2.9878277153558053e-05,
      "loss": 0.0076,
      "step": 2150
    },
    {
      "epoch": 12.078984485190409,
      "eval_loss": 0.004961056634783745,
      "eval_runtime": 20.9098,
      "eval_samples_per_second": 2170.23,
      "eval_steps_per_second": 4.256,
      "step": 2150
    },
    {
      "epoch": 12.13540197461213,
      "grad_norm": 0.015708915889263153,
      "learning_rate": 2.9784644194756557e-05,
      "loss": 0.0075,
      "step": 2160
    },
    {
      "epoch": 12.19181946403385,
      "grad_norm": 0.011568259447813034,
      "learning_rate": 2.969101123595506e-05,
      "loss": 0.0075,
      "step": 2170
    },
    {
      "epoch": 12.24823695345557,
      "grad_norm": 0.018880512565374374,
      "learning_rate": 2.959737827715356e-05,
      "loss": 0.0076,
      "step": 2180
    },
    {
      "epoch": 12.304654442877291,
      "grad_norm": 0.01510696206241846,
      "learning_rate": 2.950374531835206e-05,
      "loss": 0.0074,
      "step": 2190
    },
    {
      "epoch": 12.361071932299012,
      "grad_norm": 0.00972652342170477,
      "learning_rate": 2.9410112359550562e-05,
      "loss": 0.0076,
      "step": 2200
    },
    {
      "epoch": 12.361071932299012,
      "eval_loss": 0.0048865326680243015,
      "eval_runtime": 21.1584,
      "eval_samples_per_second": 2144.732,
      "eval_steps_per_second": 4.206,
      "step": 2200
    },
    {
      "epoch": 12.417489421720733,
      "grad_norm": 0.016387075185775757,
      "learning_rate": 2.9316479400749064e-05,
      "loss": 0.0074,
      "step": 2210
    },
    {
      "epoch": 12.473906911142453,
      "grad_norm": 0.013243873603641987,
      "learning_rate": 2.9222846441947565e-05,
      "loss": 0.0075,
      "step": 2220
    },
    {
      "epoch": 12.530324400564174,
      "grad_norm": 0.007846363820135593,
      "learning_rate": 2.9129213483146066e-05,
      "loss": 0.0074,
      "step": 2230
    },
    {
      "epoch": 12.586741889985895,
      "grad_norm": 0.01632075011730194,
      "learning_rate": 2.9035580524344567e-05,
      "loss": 0.0073,
      "step": 2240
    },
    {
      "epoch": 12.643159379407617,
      "grad_norm": 0.013586598448455334,
      "learning_rate": 2.8941947565543072e-05,
      "loss": 0.0075,
      "step": 2250
    },
    {
      "epoch": 12.643159379407617,
      "eval_loss": 0.004819327034056187,
      "eval_runtime": 21.4029,
      "eval_samples_per_second": 2120.231,
      "eval_steps_per_second": 4.158,
      "step": 2250
    },
    {
      "epoch": 12.699576868829338,
      "grad_norm": 0.01514581311494112,
      "learning_rate": 2.8848314606741573e-05,
      "loss": 0.0074,
      "step": 2260
    },
    {
      "epoch": 12.755994358251058,
      "grad_norm": 0.01725814677774906,
      "learning_rate": 2.8754681647940075e-05,
      "loss": 0.0075,
      "step": 2270
    },
    {
      "epoch": 12.812411847672779,
      "grad_norm": 0.011794638819992542,
      "learning_rate": 2.8661048689138576e-05,
      "loss": 0.0074,
      "step": 2280
    },
    {
      "epoch": 12.8688293370945,
      "grad_norm": 0.013850587420165539,
      "learning_rate": 2.8567415730337084e-05,
      "loss": 0.0074,
      "step": 2290
    },
    {
      "epoch": 12.92524682651622,
      "grad_norm": 0.009051598608493805,
      "learning_rate": 2.8473782771535585e-05,
      "loss": 0.0074,
      "step": 2300
    },
    {
      "epoch": 12.92524682651622,
      "eval_loss": 0.004802188836038113,
      "eval_runtime": 21.5547,
      "eval_samples_per_second": 2105.292,
      "eval_steps_per_second": 4.129,
      "step": 2300
    },
    {
      "epoch": 12.981664315937941,
      "grad_norm": 0.013566318899393082,
      "learning_rate": 2.8380149812734086e-05,
      "loss": 0.0073,
      "step": 2310
    },
    {
      "epoch": 13.033850493653032,
      "grad_norm": 0.012128399685025215,
      "learning_rate": 2.8286516853932588e-05,
      "loss": 0.0074,
      "step": 2320
    },
    {
      "epoch": 13.090267983074753,
      "grad_norm": 0.01255172397941351,
      "learning_rate": 2.819288389513109e-05,
      "loss": 0.0074,
      "step": 2330
    },
    {
      "epoch": 13.146685472496474,
      "grad_norm": 0.01598498225212097,
      "learning_rate": 2.809925093632959e-05,
      "loss": 0.0074,
      "step": 2340
    },
    {
      "epoch": 13.203102961918194,
      "grad_norm": 0.01952439546585083,
      "learning_rate": 2.800561797752809e-05,
      "loss": 0.0073,
      "step": 2350
    },
    {
      "epoch": 13.203102961918194,
      "eval_loss": 0.0048003774136304855,
      "eval_runtime": 20.8891,
      "eval_samples_per_second": 2172.38,
      "eval_steps_per_second": 4.261,
      "step": 2350
    },
    {
      "epoch": 13.259520451339915,
      "grad_norm": 0.01155551802366972,
      "learning_rate": 2.7911985018726593e-05,
      "loss": 0.0073,
      "step": 2360
    },
    {
      "epoch": 13.315937940761636,
      "grad_norm": 0.011209086515009403,
      "learning_rate": 2.7818352059925097e-05,
      "loss": 0.0073,
      "step": 2370
    },
    {
      "epoch": 13.372355430183356,
      "grad_norm": 0.011745181865990162,
      "learning_rate": 2.77247191011236e-05,
      "loss": 0.0073,
      "step": 2380
    },
    {
      "epoch": 13.428772919605077,
      "grad_norm": 0.011227065697312355,
      "learning_rate": 2.76310861423221e-05,
      "loss": 0.0073,
      "step": 2390
    },
    {
      "epoch": 13.485190409026798,
      "grad_norm": 0.013392379507422447,
      "learning_rate": 2.75374531835206e-05,
      "loss": 0.0073,
      "step": 2400
    },
    {
      "epoch": 13.485190409026798,
      "eval_loss": 0.004765189252793789,
      "eval_runtime": 21.3552,
      "eval_samples_per_second": 2124.959,
      "eval_steps_per_second": 4.168,
      "step": 2400
    },
    {
      "epoch": 13.541607898448518,
      "grad_norm": 0.00794807355850935,
      "learning_rate": 2.7443820224719102e-05,
      "loss": 0.0072,
      "step": 2410
    },
    {
      "epoch": 13.59802538787024,
      "grad_norm": 0.01264252420514822,
      "learning_rate": 2.7350187265917604e-05,
      "loss": 0.0072,
      "step": 2420
    },
    {
      "epoch": 13.654442877291961,
      "grad_norm": 0.013237224891781807,
      "learning_rate": 2.7256554307116105e-05,
      "loss": 0.0073,
      "step": 2430
    },
    {
      "epoch": 13.710860366713682,
      "grad_norm": 0.009013166651129723,
      "learning_rate": 2.7162921348314606e-05,
      "loss": 0.0072,
      "step": 2440
    },
    {
      "epoch": 13.767277856135403,
      "grad_norm": 0.01126518752425909,
      "learning_rate": 2.7069288389513107e-05,
      "loss": 0.0072,
      "step": 2450
    },
    {
      "epoch": 13.767277856135403,
      "eval_loss": 0.004734559450298548,
      "eval_runtime": 21.4267,
      "eval_samples_per_second": 2117.875,
      "eval_steps_per_second": 4.154,
      "step": 2450
    },
    {
      "epoch": 13.823695345557123,
      "grad_norm": 0.010502702556550503,
      "learning_rate": 2.6975655430711612e-05,
      "loss": 0.0072,
      "step": 2460
    },
    {
      "epoch": 13.880112834978844,
      "grad_norm": 0.015025006607174873,
      "learning_rate": 2.6882022471910113e-05,
      "loss": 0.0071,
      "step": 2470
    },
    {
      "epoch": 13.936530324400564,
      "grad_norm": 0.01076293084770441,
      "learning_rate": 2.6788389513108615e-05,
      "loss": 0.0071,
      "step": 2480
    },
    {
      "epoch": 13.992947813822285,
      "grad_norm": 0.014959423802793026,
      "learning_rate": 2.6694756554307116e-05,
      "loss": 0.0072,
      "step": 2490
    },
    {
      "epoch": 14.045133991537377,
      "grad_norm": 0.015351526439189911,
      "learning_rate": 2.6601123595505617e-05,
      "loss": 0.0072,
      "step": 2500
    },
    {
      "epoch": 14.045133991537377,
      "eval_loss": 0.004700013902038336,
      "eval_runtime": 20.5998,
      "eval_samples_per_second": 2202.887,
      "eval_steps_per_second": 4.32,
      "step": 2500
    },
    {
      "epoch": 14.101551480959097,
      "grad_norm": 0.007502389140427113,
      "learning_rate": 2.650749063670412e-05,
      "loss": 0.0071,
      "step": 2510
    },
    {
      "epoch": 14.157968970380818,
      "grad_norm": 0.011293509975075722,
      "learning_rate": 2.641385767790262e-05,
      "loss": 0.0071,
      "step": 2520
    },
    {
      "epoch": 14.214386459802538,
      "grad_norm": 0.011114310473203659,
      "learning_rate": 2.6320224719101128e-05,
      "loss": 0.0071,
      "step": 2530
    },
    {
      "epoch": 14.270803949224259,
      "grad_norm": 0.01338929869234562,
      "learning_rate": 2.622659176029963e-05,
      "loss": 0.0071,
      "step": 2540
    },
    {
      "epoch": 14.32722143864598,
      "grad_norm": 0.014730244874954224,
      "learning_rate": 2.613295880149813e-05,
      "loss": 0.007,
      "step": 2550
    },
    {
      "epoch": 14.32722143864598,
      "eval_loss": 0.004679370671510696,
      "eval_runtime": 21.2959,
      "eval_samples_per_second": 2130.88,
      "eval_steps_per_second": 4.179,
      "step": 2550
    },
    {
      "epoch": 14.3836389280677,
      "grad_norm": 0.01129897404462099,
      "learning_rate": 2.603932584269663e-05,
      "loss": 0.0071,
      "step": 2560
    },
    {
      "epoch": 14.440056417489421,
      "grad_norm": 0.014584062620997429,
      "learning_rate": 2.5945692883895133e-05,
      "loss": 0.0071,
      "step": 2570
    },
    {
      "epoch": 14.496473906911142,
      "grad_norm": 0.010114272125065327,
      "learning_rate": 2.5852059925093637e-05,
      "loss": 0.0071,
      "step": 2580
    },
    {
      "epoch": 14.552891396332864,
      "grad_norm": 0.011994145810604095,
      "learning_rate": 2.575842696629214e-05,
      "loss": 0.0072,
      "step": 2590
    },
    {
      "epoch": 14.609308885754585,
      "grad_norm": 0.01258955616503954,
      "learning_rate": 2.566479400749064e-05,
      "loss": 0.007,
      "step": 2600
    },
    {
      "epoch": 14.609308885754585,
      "eval_loss": 0.004642415326088667,
      "eval_runtime": 21.0389,
      "eval_samples_per_second": 2156.913,
      "eval_steps_per_second": 4.23,
      "step": 2600
    },
    {
      "epoch": 14.665726375176305,
      "grad_norm": 0.012625297531485558,
      "learning_rate": 2.557116104868914e-05,
      "loss": 0.0071,
      "step": 2610
    },
    {
      "epoch": 14.722143864598026,
      "grad_norm": 0.013649534434080124,
      "learning_rate": 2.5477528089887642e-05,
      "loss": 0.0071,
      "step": 2620
    },
    {
      "epoch": 14.778561354019747,
      "grad_norm": 0.013644597493112087,
      "learning_rate": 2.5383895131086144e-05,
      "loss": 0.0071,
      "step": 2630
    },
    {
      "epoch": 14.834978843441467,
      "grad_norm": 0.02075285278260708,
      "learning_rate": 2.5290262172284645e-05,
      "loss": 0.007,
      "step": 2640
    },
    {
      "epoch": 14.891396332863188,
      "grad_norm": 0.019490418955683708,
      "learning_rate": 2.5196629213483146e-05,
      "loss": 0.0072,
      "step": 2650
    },
    {
      "epoch": 14.891396332863188,
      "eval_loss": 0.004668313078582287,
      "eval_runtime": 21.3112,
      "eval_samples_per_second": 2129.353,
      "eval_steps_per_second": 4.176,
      "step": 2650
    },
    {
      "epoch": 14.947813822284909,
      "grad_norm": 0.01074076909571886,
      "learning_rate": 2.5102996254681647e-05,
      "loss": 0.0071,
      "step": 2660
    },
    {
      "epoch": 15.0,
      "grad_norm": 0.01867854967713356,
      "learning_rate": 2.5009363295880152e-05,
      "loss": 0.0071,
      "step": 2670
    },
    {
      "epoch": 15.05641748942172,
      "grad_norm": 0.009806040674448013,
      "learning_rate": 2.4915730337078653e-05,
      "loss": 0.007,
      "step": 2680
    },
    {
      "epoch": 15.112834978843441,
      "grad_norm": 0.009316980838775635,
      "learning_rate": 2.4822097378277155e-05,
      "loss": 0.0071,
      "step": 2690
    },
    {
      "epoch": 15.169252468265162,
      "grad_norm": 0.0075678289867937565,
      "learning_rate": 2.4728464419475656e-05,
      "loss": 0.007,
      "step": 2700
    },
    {
      "epoch": 15.169252468265162,
      "eval_loss": 0.004668894223868847,
      "eval_runtime": 21.1419,
      "eval_samples_per_second": 2146.402,
      "eval_steps_per_second": 4.21,
      "step": 2700
    },
    {
      "epoch": 15.225669957686883,
      "grad_norm": 0.009648213163018227,
      "learning_rate": 2.463483146067416e-05,
      "loss": 0.007,
      "step": 2710
    },
    {
      "epoch": 15.282087447108603,
      "grad_norm": 0.009189413860440254,
      "learning_rate": 2.4541198501872662e-05,
      "loss": 0.007,
      "step": 2720
    },
    {
      "epoch": 15.338504936530324,
      "grad_norm": 0.011326661333441734,
      "learning_rate": 2.4447565543071163e-05,
      "loss": 0.0071,
      "step": 2730
    },
    {
      "epoch": 15.394922425952045,
      "grad_norm": 0.01007761899381876,
      "learning_rate": 2.4353932584269664e-05,
      "loss": 0.007,
      "step": 2740
    },
    {
      "epoch": 15.451339915373765,
      "grad_norm": 0.012686518020927906,
      "learning_rate": 2.4260299625468166e-05,
      "loss": 0.007,
      "step": 2750
    },
    {
      "epoch": 15.451339915373765,
      "eval_loss": 0.004608229734003544,
      "eval_runtime": 21.4633,
      "eval_samples_per_second": 2114.264,
      "eval_steps_per_second": 4.147,
      "step": 2750
    },
    {
      "epoch": 15.507757404795486,
      "grad_norm": 0.013111124746501446,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 0.007,
      "step": 2760
    },
    {
      "epoch": 15.564174894217206,
      "grad_norm": 0.011733491905033588,
      "learning_rate": 2.4073033707865168e-05,
      "loss": 0.0071,
      "step": 2770
    },
    {
      "epoch": 15.620592383638929,
      "grad_norm": 0.01153633277863264,
      "learning_rate": 2.3979400749063673e-05,
      "loss": 0.007,
      "step": 2780
    },
    {
      "epoch": 15.67700987306065,
      "grad_norm": 0.012511919252574444,
      "learning_rate": 2.3885767790262174e-05,
      "loss": 0.0071,
      "step": 2790
    },
    {
      "epoch": 15.73342736248237,
      "grad_norm": 0.012058144435286522,
      "learning_rate": 2.3792134831460675e-05,
      "loss": 0.0069,
      "step": 2800
    },
    {
      "epoch": 15.73342736248237,
      "eval_loss": 0.004667791072279215,
      "eval_runtime": 21.3708,
      "eval_samples_per_second": 2123.414,
      "eval_steps_per_second": 4.165,
      "step": 2800
    },
    {
      "epoch": 15.78984485190409,
      "grad_norm": 0.009942141361534595,
      "learning_rate": 2.3698501872659176e-05,
      "loss": 0.007,
      "step": 2810
    },
    {
      "epoch": 15.846262341325811,
      "grad_norm": 0.00997837446630001,
      "learning_rate": 2.3604868913857678e-05,
      "loss": 0.007,
      "step": 2820
    },
    {
      "epoch": 15.902679830747532,
      "grad_norm": 0.017002331092953682,
      "learning_rate": 2.3511235955056182e-05,
      "loss": 0.007,
      "step": 2830
    },
    {
      "epoch": 15.959097320169253,
      "grad_norm": 0.011056691408157349,
      "learning_rate": 2.3417602996254684e-05,
      "loss": 0.0069,
      "step": 2840
    },
    {
      "epoch": 16.011283497884346,
      "grad_norm": 0.01099740993231535,
      "learning_rate": 2.3323970037453185e-05,
      "loss": 0.007,
      "step": 2850
    },
    {
      "epoch": 16.011283497884346,
      "eval_loss": 0.004654980264604092,
      "eval_runtime": 21.1546,
      "eval_samples_per_second": 2145.112,
      "eval_steps_per_second": 4.207,
      "step": 2850
    },
    {
      "epoch": 16.067700987306065,
      "grad_norm": 0.00856092106550932,
      "learning_rate": 2.3230337078651686e-05,
      "loss": 0.007,
      "step": 2860
    },
    {
      "epoch": 16.124118476727787,
      "grad_norm": 0.009220091626048088,
      "learning_rate": 2.3136704119850187e-05,
      "loss": 0.007,
      "step": 2870
    },
    {
      "epoch": 16.180535966149506,
      "grad_norm": 0.012788304127752781,
      "learning_rate": 2.3043071161048692e-05,
      "loss": 0.007,
      "step": 2880
    },
    {
      "epoch": 16.23695345557123,
      "grad_norm": 0.013496995903551579,
      "learning_rate": 2.2949438202247193e-05,
      "loss": 0.007,
      "step": 2890
    },
    {
      "epoch": 16.293370944992947,
      "grad_norm": 0.013211650773882866,
      "learning_rate": 2.2855805243445695e-05,
      "loss": 0.0069,
      "step": 2900
    },
    {
      "epoch": 16.293370944992947,
      "eval_loss": 0.0046326653100550175,
      "eval_runtime": 21.409,
      "eval_samples_per_second": 2119.621,
      "eval_steps_per_second": 4.157,
      "step": 2900
    },
    {
      "epoch": 16.34978843441467,
      "grad_norm": 0.012431659735739231,
      "learning_rate": 2.2762172284644196e-05,
      "loss": 0.0069,
      "step": 2910
    },
    {
      "epoch": 16.40620592383639,
      "grad_norm": 0.01699882745742798,
      "learning_rate": 2.2668539325842697e-05,
      "loss": 0.007,
      "step": 2920
    },
    {
      "epoch": 16.46262341325811,
      "grad_norm": 0.009919950738549232,
      "learning_rate": 2.25749063670412e-05,
      "loss": 0.007,
      "step": 2930
    },
    {
      "epoch": 16.51904090267983,
      "grad_norm": 0.009562728926539421,
      "learning_rate": 2.24812734082397e-05,
      "loss": 0.0069,
      "step": 2940
    },
    {
      "epoch": 16.575458392101552,
      "grad_norm": 0.010446048341691494,
      "learning_rate": 2.23876404494382e-05,
      "loss": 0.0069,
      "step": 2950
    },
    {
      "epoch": 16.575458392101552,
      "eval_loss": 0.004608639050275087,
      "eval_runtime": 21.4971,
      "eval_samples_per_second": 2110.939,
      "eval_steps_per_second": 4.14,
      "step": 2950
    },
    {
      "epoch": 16.63187588152327,
      "grad_norm": 0.00896051898598671,
      "learning_rate": 2.2294007490636706e-05,
      "loss": 0.007,
      "step": 2960
    },
    {
      "epoch": 16.688293370944994,
      "grad_norm": 0.011980070732533932,
      "learning_rate": 2.2200374531835207e-05,
      "loss": 0.0069,
      "step": 2970
    },
    {
      "epoch": 16.744710860366713,
      "grad_norm": 0.010512067936360836,
      "learning_rate": 2.2106741573033708e-05,
      "loss": 0.0068,
      "step": 2980
    },
    {
      "epoch": 16.801128349788435,
      "grad_norm": 0.011387849226593971,
      "learning_rate": 2.2013108614232213e-05,
      "loss": 0.0068,
      "step": 2990
    },
    {
      "epoch": 16.857545839210154,
      "grad_norm": 0.00841585174202919,
      "learning_rate": 2.1919475655430714e-05,
      "loss": 0.0068,
      "step": 3000
    },
    {
      "epoch": 16.857545839210154,
      "eval_loss": 0.004594268277287483,
      "eval_runtime": 21.3306,
      "eval_samples_per_second": 2127.413,
      "eval_steps_per_second": 4.172,
      "step": 3000
    },
    {
      "epoch": 16.913963328631876,
      "grad_norm": 0.009429479017853737,
      "learning_rate": 2.1825842696629215e-05,
      "loss": 0.007,
      "step": 3010
    },
    {
      "epoch": 16.970380818053595,
      "grad_norm": 0.01458224281668663,
      "learning_rate": 2.1732209737827716e-05,
      "loss": 0.0069,
      "step": 3020
    },
    {
      "epoch": 17.02256699576869,
      "grad_norm": 0.010593947023153305,
      "learning_rate": 2.1638576779026218e-05,
      "loss": 0.0068,
      "step": 3030
    },
    {
      "epoch": 17.07898448519041,
      "grad_norm": 0.011720913462340832,
      "learning_rate": 2.154494382022472e-05,
      "loss": 0.0068,
      "step": 3040
    },
    {
      "epoch": 17.13540197461213,
      "grad_norm": 0.014540059491991997,
      "learning_rate": 2.145131086142322e-05,
      "loss": 0.0068,
      "step": 3050
    },
    {
      "epoch": 17.13540197461213,
      "eval_loss": 0.004583429079502821,
      "eval_runtime": 20.6643,
      "eval_samples_per_second": 2196.005,
      "eval_steps_per_second": 4.307,
      "step": 3050
    },
    {
      "epoch": 17.191819464033852,
      "grad_norm": 0.009510737843811512,
      "learning_rate": 2.135767790262172e-05,
      "loss": 0.0069,
      "step": 3060
    },
    {
      "epoch": 17.24823695345557,
      "grad_norm": 0.010390340350568295,
      "learning_rate": 2.1264044943820223e-05,
      "loss": 0.0069,
      "step": 3070
    },
    {
      "epoch": 17.304654442877293,
      "grad_norm": 0.014903599396348,
      "learning_rate": 2.1170411985018727e-05,
      "loss": 0.0068,
      "step": 3080
    },
    {
      "epoch": 17.361071932299012,
      "grad_norm": 0.01549824420362711,
      "learning_rate": 2.1076779026217232e-05,
      "loss": 0.0069,
      "step": 3090
    },
    {
      "epoch": 17.417489421720735,
      "grad_norm": 0.00984672550112009,
      "learning_rate": 2.0983146067415733e-05,
      "loss": 0.0069,
      "step": 3100
    },
    {
      "epoch": 17.417489421720735,
      "eval_loss": 0.004607572220265865,
      "eval_runtime": 21.3664,
      "eval_samples_per_second": 2123.849,
      "eval_steps_per_second": 4.165,
      "step": 3100
    },
    {
      "epoch": 17.473906911142453,
      "grad_norm": 0.020549841225147247,
      "learning_rate": 2.0889513108614235e-05,
      "loss": 0.0069,
      "step": 3110
    },
    {
      "epoch": 17.530324400564176,
      "grad_norm": 0.010608705691993237,
      "learning_rate": 2.0795880149812736e-05,
      "loss": 0.0068,
      "step": 3120
    },
    {
      "epoch": 17.586741889985895,
      "grad_norm": 0.009010777808725834,
      "learning_rate": 2.0702247191011237e-05,
      "loss": 0.0068,
      "step": 3130
    },
    {
      "epoch": 17.643159379407617,
      "grad_norm": 0.009873360395431519,
      "learning_rate": 2.060861423220974e-05,
      "loss": 0.0069,
      "step": 3140
    },
    {
      "epoch": 17.699576868829336,
      "grad_norm": 0.010192418470978737,
      "learning_rate": 2.051498127340824e-05,
      "loss": 0.0069,
      "step": 3150
    },
    {
      "epoch": 17.699576868829336,
      "eval_loss": 0.004574202001094818,
      "eval_runtime": 21.456,
      "eval_samples_per_second": 2114.981,
      "eval_steps_per_second": 4.148,
      "step": 3150
    },
    {
      "epoch": 17.75599435825106,
      "grad_norm": 0.011187477968633175,
      "learning_rate": 2.042134831460674e-05,
      "loss": 0.0069,
      "step": 3160
    },
    {
      "epoch": 17.812411847672777,
      "grad_norm": 0.013230564072728157,
      "learning_rate": 2.0327715355805242e-05,
      "loss": 0.0068,
      "step": 3170
    },
    {
      "epoch": 17.8688293370945,
      "grad_norm": 0.010104231536388397,
      "learning_rate": 2.0234082397003747e-05,
      "loss": 0.0068,
      "step": 3180
    },
    {
      "epoch": 17.92524682651622,
      "grad_norm": 0.009503635577857494,
      "learning_rate": 2.0140449438202248e-05,
      "loss": 0.0068,
      "step": 3190
    },
    {
      "epoch": 17.98166431593794,
      "grad_norm": 0.010313868522644043,
      "learning_rate": 2.0046816479400753e-05,
      "loss": 0.0069,
      "step": 3200
    },
    {
      "epoch": 17.98166431593794,
      "eval_loss": 0.004590082913637161,
      "eval_runtime": 21.3317,
      "eval_samples_per_second": 2127.308,
      "eval_steps_per_second": 4.172,
      "step": 3200
    },
    {
      "epoch": 18.033850493653034,
      "grad_norm": 0.015034486539661884,
      "learning_rate": 1.9953183520599254e-05,
      "loss": 0.0069,
      "step": 3210
    },
    {
      "epoch": 18.090267983074753,
      "grad_norm": 0.014333277940750122,
      "learning_rate": 1.9859550561797755e-05,
      "loss": 0.0067,
      "step": 3220
    },
    {
      "epoch": 18.146685472496475,
      "grad_norm": 0.010950061492621899,
      "learning_rate": 1.9765917602996256e-05,
      "loss": 0.0069,
      "step": 3230
    },
    {
      "epoch": 18.203102961918194,
      "grad_norm": 0.010805698111653328,
      "learning_rate": 1.9672284644194758e-05,
      "loss": 0.0068,
      "step": 3240
    },
    {
      "epoch": 18.259520451339917,
      "grad_norm": 0.01095818541944027,
      "learning_rate": 1.957865168539326e-05,
      "loss": 0.0068,
      "step": 3250
    },
    {
      "epoch": 18.259520451339917,
      "eval_loss": 0.0045674326829612255,
      "eval_runtime": 21.2833,
      "eval_samples_per_second": 2132.142,
      "eval_steps_per_second": 4.182,
      "step": 3250
    },
    {
      "epoch": 18.315937940761636,
      "grad_norm": 0.009185048751533031,
      "learning_rate": 1.948501872659176e-05,
      "loss": 0.0068,
      "step": 3260
    },
    {
      "epoch": 18.372355430183358,
      "grad_norm": 0.010980081744492054,
      "learning_rate": 1.939138576779026e-05,
      "loss": 0.0067,
      "step": 3270
    },
    {
      "epoch": 18.428772919605077,
      "grad_norm": 0.009368693456053734,
      "learning_rate": 1.9297752808988763e-05,
      "loss": 0.0068,
      "step": 3280
    },
    {
      "epoch": 18.4851904090268,
      "grad_norm": 0.008411162532866001,
      "learning_rate": 1.9204119850187267e-05,
      "loss": 0.0068,
      "step": 3290
    },
    {
      "epoch": 18.541607898448518,
      "grad_norm": 0.012781689874827862,
      "learning_rate": 1.911048689138577e-05,
      "loss": 0.0068,
      "step": 3300
    },
    {
      "epoch": 18.541607898448518,
      "eval_loss": 0.004545554053038359,
      "eval_runtime": 21.4955,
      "eval_samples_per_second": 2111.093,
      "eval_steps_per_second": 4.14,
      "step": 3300
    },
    {
      "epoch": 18.59802538787024,
      "grad_norm": 0.008481228724122047,
      "learning_rate": 1.901685393258427e-05,
      "loss": 0.0067,
      "step": 3310
    },
    {
      "epoch": 18.65444287729196,
      "grad_norm": 0.010841197334229946,
      "learning_rate": 1.8923220973782775e-05,
      "loss": 0.0068,
      "step": 3320
    },
    {
      "epoch": 18.710860366713682,
      "grad_norm": 0.010081646963953972,
      "learning_rate": 1.8829588014981276e-05,
      "loss": 0.0068,
      "step": 3330
    },
    {
      "epoch": 18.7672778561354,
      "grad_norm": 0.007739570923149586,
      "learning_rate": 1.8735955056179777e-05,
      "loss": 0.0068,
      "step": 3340
    },
    {
      "epoch": 18.823695345557123,
      "grad_norm": 0.00890689343214035,
      "learning_rate": 1.864232209737828e-05,
      "loss": 0.0067,
      "step": 3350
    },
    {
      "epoch": 18.823695345557123,
      "eval_loss": 0.004577449057251215,
      "eval_runtime": 21.5385,
      "eval_samples_per_second": 2106.874,
      "eval_steps_per_second": 4.132,
      "step": 3350
    },
    {
      "epoch": 18.880112834978842,
      "grad_norm": 0.010219233110547066,
      "learning_rate": 1.854868913857678e-05,
      "loss": 0.0068,
      "step": 3360
    },
    {
      "epoch": 18.936530324400564,
      "grad_norm": 0.011067194864153862,
      "learning_rate": 1.845505617977528e-05,
      "loss": 0.0067,
      "step": 3370
    },
    {
      "epoch": 18.992947813822283,
      "grad_norm": 0.008476832881569862,
      "learning_rate": 1.8361423220973782e-05,
      "loss": 0.0068,
      "step": 3380
    },
    {
      "epoch": 19.045133991537377,
      "grad_norm": 0.014057529158890247,
      "learning_rate": 1.8267790262172287e-05,
      "loss": 0.0068,
      "step": 3390
    },
    {
      "epoch": 19.1015514809591,
      "grad_norm": 0.011327750980854034,
      "learning_rate": 1.8174157303370788e-05,
      "loss": 0.0068,
      "step": 3400
    },
    {
      "epoch": 19.1015514809591,
      "eval_loss": 0.004553158767521381,
      "eval_runtime": 21.1405,
      "eval_samples_per_second": 2146.543,
      "eval_steps_per_second": 4.21,
      "step": 3400
    },
    {
      "epoch": 19.157968970380818,
      "grad_norm": 0.009585334919393063,
      "learning_rate": 1.808052434456929e-05,
      "loss": 0.0068,
      "step": 3410
    },
    {
      "epoch": 19.21438645980254,
      "grad_norm": 0.010073096491396427,
      "learning_rate": 1.798689138576779e-05,
      "loss": 0.0068,
      "step": 3420
    },
    {
      "epoch": 19.27080394922426,
      "grad_norm": 0.009759904816746712,
      "learning_rate": 1.7893258426966292e-05,
      "loss": 0.0066,
      "step": 3430
    },
    {
      "epoch": 19.32722143864598,
      "grad_norm": 0.016972409561276436,
      "learning_rate": 1.7799625468164796e-05,
      "loss": 0.0068,
      "step": 3440
    },
    {
      "epoch": 19.3836389280677,
      "grad_norm": 0.011586218141019344,
      "learning_rate": 1.7705992509363298e-05,
      "loss": 0.0068,
      "step": 3450
    },
    {
      "epoch": 19.3836389280677,
      "eval_loss": 0.0045377882197499275,
      "eval_runtime": 21.17,
      "eval_samples_per_second": 2143.549,
      "eval_steps_per_second": 4.204,
      "step": 3450
    },
    {
      "epoch": 19.440056417489423,
      "grad_norm": 0.011667800135910511,
      "learning_rate": 1.76123595505618e-05,
      "loss": 0.0067,
      "step": 3460
    },
    {
      "epoch": 19.49647390691114,
      "grad_norm": 0.00995556265115738,
      "learning_rate": 1.75187265917603e-05,
      "loss": 0.0067,
      "step": 3470
    },
    {
      "epoch": 19.552891396332864,
      "grad_norm": 0.015883803367614746,
      "learning_rate": 1.74250936329588e-05,
      "loss": 0.0067,
      "step": 3480
    },
    {
      "epoch": 19.609308885754583,
      "grad_norm": 0.014428754337131977,
      "learning_rate": 1.7331460674157303e-05,
      "loss": 0.0068,
      "step": 3490
    },
    {
      "epoch": 19.665726375176305,
      "grad_norm": 0.013285205699503422,
      "learning_rate": 1.7237827715355807e-05,
      "loss": 0.0068,
      "step": 3500
    },
    {
      "epoch": 19.665726375176305,
      "eval_loss": 0.004572625271975994,
      "eval_runtime": 21.3129,
      "eval_samples_per_second": 2129.177,
      "eval_steps_per_second": 4.176,
      "step": 3500
    },
    {
      "epoch": 19.722143864598024,
      "grad_norm": 0.013580573722720146,
      "learning_rate": 1.714419475655431e-05,
      "loss": 0.0067,
      "step": 3510
    },
    {
      "epoch": 19.778561354019747,
      "grad_norm": 0.01037775818258524,
      "learning_rate": 1.705056179775281e-05,
      "loss": 0.0067,
      "step": 3520
    },
    {
      "epoch": 19.834978843441466,
      "grad_norm": 0.011963781900703907,
      "learning_rate": 1.695692883895131e-05,
      "loss": 0.0068,
      "step": 3530
    },
    {
      "epoch": 19.891396332863188,
      "grad_norm": 0.012019743211567402,
      "learning_rate": 1.6863295880149812e-05,
      "loss": 0.0068,
      "step": 3540
    },
    {
      "epoch": 19.947813822284907,
      "grad_norm": 0.009781966917216778,
      "learning_rate": 1.6769662921348314e-05,
      "loss": 0.0067,
      "step": 3550
    },
    {
      "epoch": 19.947813822284907,
      "eval_loss": 0.004535302519798279,
      "eval_runtime": 21.3288,
      "eval_samples_per_second": 2127.592,
      "eval_steps_per_second": 4.173,
      "step": 3550
    },
    {
      "epoch": 20.0,
      "grad_norm": 0.019939610734581947,
      "learning_rate": 1.667602996254682e-05,
      "loss": 0.0067,
      "step": 3560
    },
    {
      "epoch": 20.056417489421722,
      "grad_norm": 0.010547725483775139,
      "learning_rate": 1.658239700374532e-05,
      "loss": 0.0067,
      "step": 3570
    },
    {
      "epoch": 20.11283497884344,
      "grad_norm": 0.00953550823032856,
      "learning_rate": 1.648876404494382e-05,
      "loss": 0.0067,
      "step": 3580
    },
    {
      "epoch": 20.169252468265164,
      "grad_norm": 0.009238969534635544,
      "learning_rate": 1.6395131086142322e-05,
      "loss": 0.0068,
      "step": 3590
    },
    {
      "epoch": 20.225669957686883,
      "grad_norm": 0.010778083465993404,
      "learning_rate": 1.6301498127340827e-05,
      "loss": 0.0067,
      "step": 3600
    },
    {
      "epoch": 20.225669957686883,
      "eval_loss": 0.004539838060736656,
      "eval_runtime": 21.0239,
      "eval_samples_per_second": 2158.453,
      "eval_steps_per_second": 4.233,
      "step": 3600
    },
    {
      "epoch": 20.282087447108605,
      "grad_norm": 0.007239213678985834,
      "learning_rate": 1.6207865168539328e-05,
      "loss": 0.0067,
      "step": 3610
    },
    {
      "epoch": 20.338504936530324,
      "grad_norm": 0.01062082964926958,
      "learning_rate": 1.611423220973783e-05,
      "loss": 0.0067,
      "step": 3620
    },
    {
      "epoch": 20.394922425952046,
      "grad_norm": 0.014569696970283985,
      "learning_rate": 1.602059925093633e-05,
      "loss": 0.0066,
      "step": 3630
    },
    {
      "epoch": 20.451339915373765,
      "grad_norm": 0.012655263766646385,
      "learning_rate": 1.5926966292134832e-05,
      "loss": 0.0066,
      "step": 3640
    },
    {
      "epoch": 20.507757404795488,
      "grad_norm": 0.010987602174282074,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 0.0067,
      "step": 3650
    },
    {
      "epoch": 20.507757404795488,
      "eval_loss": 0.0045229485258460045,
      "eval_runtime": 21.3249,
      "eval_samples_per_second": 2127.985,
      "eval_steps_per_second": 4.174,
      "step": 3650
    },
    {
      "epoch": 20.564174894217206,
      "grad_norm": 0.009018042124807835,
      "learning_rate": 1.5739700374531834e-05,
      "loss": 0.0067,
      "step": 3660
    },
    {
      "epoch": 20.62059238363893,
      "grad_norm": 0.008308966644108295,
      "learning_rate": 1.5646067415730336e-05,
      "loss": 0.0067,
      "step": 3670
    },
    {
      "epoch": 20.677009873060648,
      "grad_norm": 0.009930637665092945,
      "learning_rate": 1.555243445692884e-05,
      "loss": 0.0067,
      "step": 3680
    },
    {
      "epoch": 20.73342736248237,
      "grad_norm": 0.010100294835865498,
      "learning_rate": 1.545880149812734e-05,
      "loss": 0.0066,
      "step": 3690
    },
    {
      "epoch": 20.78984485190409,
      "grad_norm": 0.012132094241678715,
      "learning_rate": 1.5365168539325843e-05,
      "loss": 0.0068,
      "step": 3700
    },
    {
      "epoch": 20.78984485190409,
      "eval_loss": 0.00455709220841527,
      "eval_runtime": 21.5974,
      "eval_samples_per_second": 2101.133,
      "eval_steps_per_second": 4.121,
      "step": 3700
    },
    {
      "epoch": 20.84626234132581,
      "grad_norm": 0.013034014031291008,
      "learning_rate": 1.5271535580524347e-05,
      "loss": 0.0067,
      "step": 3710
    },
    {
      "epoch": 20.90267983074753,
      "grad_norm": 0.009263022802770138,
      "learning_rate": 1.5177902621722847e-05,
      "loss": 0.0066,
      "step": 3720
    },
    {
      "epoch": 20.959097320169253,
      "grad_norm": 0.012793556787073612,
      "learning_rate": 1.508426966292135e-05,
      "loss": 0.0067,
      "step": 3730
    },
    {
      "epoch": 21.011283497884346,
      "grad_norm": 0.013199394568800926,
      "learning_rate": 1.4990636704119851e-05,
      "loss": 0.0067,
      "step": 3740
    },
    {
      "epoch": 21.067700987306065,
      "grad_norm": 0.010622723028063774,
      "learning_rate": 1.4897003745318352e-05,
      "loss": 0.0067,
      "step": 3750
    },
    {
      "epoch": 21.067700987306065,
      "eval_loss": 0.004513060674071312,
      "eval_runtime": 21.0997,
      "eval_samples_per_second": 2150.692,
      "eval_steps_per_second": 4.218,
      "step": 3750
    },
    {
      "epoch": 21.124118476727787,
      "grad_norm": 0.013067818246781826,
      "learning_rate": 1.4803370786516854e-05,
      "loss": 0.0067,
      "step": 3760
    },
    {
      "epoch": 21.180535966149506,
      "grad_norm": 0.008701044134795666,
      "learning_rate": 1.4709737827715355e-05,
      "loss": 0.0067,
      "step": 3770
    },
    {
      "epoch": 21.23695345557123,
      "grad_norm": 0.010632846504449844,
      "learning_rate": 1.4616104868913858e-05,
      "loss": 0.0067,
      "step": 3780
    },
    {
      "epoch": 21.293370944992947,
      "grad_norm": 0.0135599784553051,
      "learning_rate": 1.452247191011236e-05,
      "loss": 0.0066,
      "step": 3790
    },
    {
      "epoch": 21.34978843441467,
      "grad_norm": 0.011606946587562561,
      "learning_rate": 1.4428838951310864e-05,
      "loss": 0.0067,
      "step": 3800
    },
    {
      "epoch": 21.34978843441467,
      "eval_loss": 0.004495922941714525,
      "eval_runtime": 21.5495,
      "eval_samples_per_second": 2105.803,
      "eval_steps_per_second": 4.13,
      "step": 3800
    },
    {
      "epoch": 21.40620592383639,
      "grad_norm": 0.011222240515053272,
      "learning_rate": 1.4335205992509365e-05,
      "loss": 0.0066,
      "step": 3810
    },
    {
      "epoch": 21.46262341325811,
      "grad_norm": 0.011249981820583344,
      "learning_rate": 1.4241573033707866e-05,
      "loss": 0.0066,
      "step": 3820
    },
    {
      "epoch": 21.51904090267983,
      "grad_norm": 0.014779000543057919,
      "learning_rate": 1.4147940074906368e-05,
      "loss": 0.0067,
      "step": 3830
    },
    {
      "epoch": 21.575458392101552,
      "grad_norm": 0.008967866189777851,
      "learning_rate": 1.405430711610487e-05,
      "loss": 0.0066,
      "step": 3840
    },
    {
      "epoch": 21.63187588152327,
      "grad_norm": 0.010498832911252975,
      "learning_rate": 1.3960674157303372e-05,
      "loss": 0.0068,
      "step": 3850
    },
    {
      "epoch": 21.63187588152327,
      "eval_loss": 0.004522460978478193,
      "eval_runtime": 21.5482,
      "eval_samples_per_second": 2105.927,
      "eval_steps_per_second": 4.13,
      "step": 3850
    },
    {
      "epoch": 21.688293370944994,
      "grad_norm": 0.011344286613166332,
      "learning_rate": 1.3867041198501873e-05,
      "loss": 0.0067,
      "step": 3860
    },
    {
      "epoch": 21.744710860366713,
      "grad_norm": 0.012707922607660294,
      "learning_rate": 1.3773408239700374e-05,
      "loss": 0.0067,
      "step": 3870
    },
    {
      "epoch": 21.801128349788435,
      "grad_norm": 0.012350491248071194,
      "learning_rate": 1.3679775280898877e-05,
      "loss": 0.0067,
      "step": 3880
    },
    {
      "epoch": 21.857545839210154,
      "grad_norm": 0.007804062217473984,
      "learning_rate": 1.3586142322097379e-05,
      "loss": 0.0067,
      "step": 3890
    },
    {
      "epoch": 21.913963328631876,
      "grad_norm": 0.012651310302317142,
      "learning_rate": 1.349250936329588e-05,
      "loss": 0.0066,
      "step": 3900
    },
    {
      "epoch": 21.913963328631876,
      "eval_loss": 0.0045268177054822445,
      "eval_runtime": 21.6013,
      "eval_samples_per_second": 2100.755,
      "eval_steps_per_second": 4.12,
      "step": 3900
    },
    {
      "epoch": 21.970380818053595,
      "grad_norm": 0.012992124073207378,
      "learning_rate": 1.3398876404494381e-05,
      "loss": 0.0066,
      "step": 3910
    },
    {
      "epoch": 22.02256699576869,
      "grad_norm": 0.008686329238116741,
      "learning_rate": 1.3305243445692884e-05,
      "loss": 0.0066,
      "step": 3920
    },
    {
      "epoch": 22.07898448519041,
      "grad_norm": 0.010079197585582733,
      "learning_rate": 1.3211610486891387e-05,
      "loss": 0.0067,
      "step": 3930
    },
    {
      "epoch": 22.13540197461213,
      "grad_norm": 0.007832062430679798,
      "learning_rate": 1.311797752808989e-05,
      "loss": 0.0066,
      "step": 3940
    },
    {
      "epoch": 22.191819464033852,
      "grad_norm": 0.010979490354657173,
      "learning_rate": 1.3024344569288391e-05,
      "loss": 0.0067,
      "step": 3950
    },
    {
      "epoch": 22.191819464033852,
      "eval_loss": 0.004465759266167879,
      "eval_runtime": 21.2526,
      "eval_samples_per_second": 2135.226,
      "eval_steps_per_second": 4.188,
      "step": 3950
    },
    {
      "epoch": 22.24823695345557,
      "grad_norm": 0.0100516676902771,
      "learning_rate": 1.2930711610486892e-05,
      "loss": 0.0068,
      "step": 3960
    },
    {
      "epoch": 22.304654442877293,
      "grad_norm": 0.008873330429196358,
      "learning_rate": 1.2837078651685394e-05,
      "loss": 0.0066,
      "step": 3970
    },
    {
      "epoch": 22.361071932299012,
      "grad_norm": 0.010265211574733257,
      "learning_rate": 1.2743445692883895e-05,
      "loss": 0.0067,
      "step": 3980
    },
    {
      "epoch": 22.417489421720735,
      "grad_norm": 0.011817398481070995,
      "learning_rate": 1.2649812734082398e-05,
      "loss": 0.0066,
      "step": 3990
    },
    {
      "epoch": 22.473906911142453,
      "grad_norm": 0.011301311664283276,
      "learning_rate": 1.25561797752809e-05,
      "loss": 0.0066,
      "step": 4000
    },
    {
      "epoch": 22.473906911142453,
      "eval_loss": 0.004504992626607418,
      "eval_runtime": 21.1725,
      "eval_samples_per_second": 2143.297,
      "eval_steps_per_second": 4.204,
      "step": 4000
    },
    {
      "epoch": 22.530324400564176,
      "grad_norm": 0.009634988382458687,
      "learning_rate": 1.24625468164794e-05,
      "loss": 0.0066,
      "step": 4010
    },
    {
      "epoch": 22.586741889985895,
      "grad_norm": 0.007276505697518587,
      "learning_rate": 1.2368913857677903e-05,
      "loss": 0.0066,
      "step": 4020
    },
    {
      "epoch": 22.643159379407617,
      "grad_norm": 0.011762372218072414,
      "learning_rate": 1.2275280898876405e-05,
      "loss": 0.0066,
      "step": 4030
    },
    {
      "epoch": 22.699576868829336,
      "grad_norm": 0.009707172401249409,
      "learning_rate": 1.2181647940074908e-05,
      "loss": 0.0066,
      "step": 4040
    },
    {
      "epoch": 22.75599435825106,
      "grad_norm": 0.007971863262355328,
      "learning_rate": 1.2088014981273409e-05,
      "loss": 0.0067,
      "step": 4050
    },
    {
      "epoch": 22.75599435825106,
      "eval_loss": 0.0045502339489758015,
      "eval_runtime": 21.2301,
      "eval_samples_per_second": 2137.481,
      "eval_steps_per_second": 4.192,
      "step": 4050
    },
    {
      "epoch": 22.812411847672777,
      "grad_norm": 0.007202629465609789,
      "learning_rate": 1.199438202247191e-05,
      "loss": 0.0065,
      "step": 4060
    },
    {
      "epoch": 22.8688293370945,
      "grad_norm": 0.018795516341924667,
      "learning_rate": 1.1900749063670411e-05,
      "loss": 0.0066,
      "step": 4070
    },
    {
      "epoch": 22.92524682651622,
      "grad_norm": 0.009910563938319683,
      "learning_rate": 1.1807116104868914e-05,
      "loss": 0.0067,
      "step": 4080
    },
    {
      "epoch": 22.98166431593794,
      "grad_norm": 0.007456967141479254,
      "learning_rate": 1.1713483146067417e-05,
      "loss": 0.0066,
      "step": 4090
    },
    {
      "epoch": 23.033850493653034,
      "grad_norm": 0.00713193928822875,
      "learning_rate": 1.1619850187265919e-05,
      "loss": 0.0067,
      "step": 4100
    },
    {
      "epoch": 23.033850493653034,
      "eval_loss": 0.0044961837120354176,
      "eval_runtime": 20.6396,
      "eval_samples_per_second": 2198.642,
      "eval_steps_per_second": 4.312,
      "step": 4100
    },
    {
      "epoch": 23.090267983074753,
      "grad_norm": 0.010893221013247967,
      "learning_rate": 1.152621722846442e-05,
      "loss": 0.0066,
      "step": 4110
    },
    {
      "epoch": 23.146685472496475,
      "grad_norm": 0.011412400752305984,
      "learning_rate": 1.1432584269662921e-05,
      "loss": 0.0066,
      "step": 4120
    },
    {
      "epoch": 23.203102961918194,
      "grad_norm": 0.010653232224285603,
      "learning_rate": 1.1338951310861422e-05,
      "loss": 0.0067,
      "step": 4130
    },
    {
      "epoch": 23.259520451339917,
      "grad_norm": 0.008304501883685589,
      "learning_rate": 1.1245318352059927e-05,
      "loss": 0.0067,
      "step": 4140
    },
    {
      "epoch": 23.315937940761636,
      "grad_norm": 0.008278416469693184,
      "learning_rate": 1.1151685393258428e-05,
      "loss": 0.0065,
      "step": 4150
    },
    {
      "epoch": 23.315937940761636,
      "eval_loss": 0.0045078108087182045,
      "eval_runtime": 21.4877,
      "eval_samples_per_second": 2111.862,
      "eval_steps_per_second": 4.142,
      "step": 4150
    },
    {
      "epoch": 23.372355430183358,
      "grad_norm": 0.010537395253777504,
      "learning_rate": 1.105805243445693e-05,
      "loss": 0.0067,
      "step": 4160
    },
    {
      "epoch": 23.428772919605077,
      "grad_norm": 0.013279582373797894,
      "learning_rate": 1.096441947565543e-05,
      "loss": 0.0066,
      "step": 4170
    },
    {
      "epoch": 23.4851904090268,
      "grad_norm": 0.010782391764223576,
      "learning_rate": 1.0870786516853932e-05,
      "loss": 0.0066,
      "step": 4180
    },
    {
      "epoch": 23.541607898448518,
      "grad_norm": 0.008444621227681637,
      "learning_rate": 1.0777153558052435e-05,
      "loss": 0.0066,
      "step": 4190
    },
    {
      "epoch": 23.59802538787024,
      "grad_norm": 0.009822976775467396,
      "learning_rate": 1.0683520599250938e-05,
      "loss": 0.0066,
      "step": 4200
    },
    {
      "epoch": 23.59802538787024,
      "eval_loss": 0.0044861044734716415,
      "eval_runtime": 21.3921,
      "eval_samples_per_second": 2121.298,
      "eval_steps_per_second": 4.16,
      "step": 4200
    },
    {
      "epoch": 23.65444287729196,
      "grad_norm": 0.011697297915816307,
      "learning_rate": 1.058988764044944e-05,
      "loss": 0.0066,
      "step": 4210
    },
    {
      "epoch": 23.710860366713682,
      "grad_norm": 0.01103886403143406,
      "learning_rate": 1.049625468164794e-05,
      "loss": 0.0066,
      "step": 4220
    },
    {
      "epoch": 23.7672778561354,
      "grad_norm": 0.009795219637453556,
      "learning_rate": 1.0402621722846442e-05,
      "loss": 0.0065,
      "step": 4230
    },
    {
      "epoch": 23.823695345557123,
      "grad_norm": 0.008462166413664818,
      "learning_rate": 1.0308988764044945e-05,
      "loss": 0.0066,
      "step": 4240
    },
    {
      "epoch": 23.880112834978842,
      "grad_norm": 0.00937722995877266,
      "learning_rate": 1.0215355805243446e-05,
      "loss": 0.0067,
      "step": 4250
    },
    {
      "epoch": 23.880112834978842,
      "eval_loss": 0.0044904714450240135,
      "eval_runtime": 21.5032,
      "eval_samples_per_second": 2110.335,
      "eval_steps_per_second": 4.139,
      "step": 4250
    },
    {
      "epoch": 23.936530324400564,
      "grad_norm": 0.010720844380557537,
      "learning_rate": 1.0121722846441949e-05,
      "loss": 0.0066,
      "step": 4260
    },
    {
      "epoch": 23.992947813822283,
      "grad_norm": 0.010059274733066559,
      "learning_rate": 1.002808988764045e-05,
      "loss": 0.0067,
      "step": 4270
    },
    {
      "epoch": 24.045133991537377,
      "grad_norm": 0.010199116542935371,
      "learning_rate": 9.934456928838951e-06,
      "loss": 0.0066,
      "step": 4280
    },
    {
      "epoch": 24.1015514809591,
      "grad_norm": 0.008664875291287899,
      "learning_rate": 9.840823970037454e-06,
      "loss": 0.0066,
      "step": 4290
    },
    {
      "epoch": 24.157968970380818,
      "grad_norm": 0.011288091540336609,
      "learning_rate": 9.747191011235956e-06,
      "loss": 0.0066,
      "step": 4300
    },
    {
      "epoch": 24.157968970380818,
      "eval_loss": 0.004468211438506842,
      "eval_runtime": 21.1172,
      "eval_samples_per_second": 2148.916,
      "eval_steps_per_second": 4.215,
      "step": 4300
    },
    {
      "epoch": 24.21438645980254,
      "grad_norm": 0.009497069753706455,
      "learning_rate": 9.653558052434457e-06,
      "loss": 0.0065,
      "step": 4310
    },
    {
      "epoch": 24.27080394922426,
      "grad_norm": 0.01223438698798418,
      "learning_rate": 9.55992509363296e-06,
      "loss": 0.0066,
      "step": 4320
    },
    {
      "epoch": 24.32722143864598,
      "grad_norm": 0.010599835775792599,
      "learning_rate": 9.466292134831461e-06,
      "loss": 0.0066,
      "step": 4330
    },
    {
      "epoch": 24.3836389280677,
      "grad_norm": 0.012744705192744732,
      "learning_rate": 9.372659176029962e-06,
      "loss": 0.0066,
      "step": 4340
    },
    {
      "epoch": 24.440056417489423,
      "grad_norm": 0.00937556941062212,
      "learning_rate": 9.279026217228465e-06,
      "loss": 0.0068,
      "step": 4350
    },
    {
      "epoch": 24.440056417489423,
      "eval_loss": 0.004490968305617571,
      "eval_runtime": 21.2218,
      "eval_samples_per_second": 2138.317,
      "eval_steps_per_second": 4.194,
      "step": 4350
    },
    {
      "epoch": 24.49647390691114,
      "grad_norm": 0.00981039460748434,
      "learning_rate": 9.185393258426967e-06,
      "loss": 0.0067,
      "step": 4360
    },
    {
      "epoch": 24.552891396332864,
      "grad_norm": 0.006826708558946848,
      "learning_rate": 9.091760299625468e-06,
      "loss": 0.0066,
      "step": 4370
    },
    {
      "epoch": 24.609308885754583,
      "grad_norm": 0.007629010360687971,
      "learning_rate": 8.99812734082397e-06,
      "loss": 0.0066,
      "step": 4380
    },
    {
      "epoch": 24.665726375176305,
      "grad_norm": 0.00826236791908741,
      "learning_rate": 8.904494382022472e-06,
      "loss": 0.0065,
      "step": 4390
    },
    {
      "epoch": 24.722143864598024,
      "grad_norm": 0.007719255983829498,
      "learning_rate": 8.810861423220975e-06,
      "loss": 0.0066,
      "step": 4400
    },
    {
      "epoch": 24.722143864598024,
      "eval_loss": 0.004481615964323282,
      "eval_runtime": 21.766,
      "eval_samples_per_second": 2084.857,
      "eval_steps_per_second": 4.089,
      "step": 4400
    },
    {
      "epoch": 24.778561354019747,
      "grad_norm": 0.008458409458398819,
      "learning_rate": 8.717228464419476e-06,
      "loss": 0.0066,
      "step": 4410
    },
    {
      "epoch": 24.834978843441466,
      "grad_norm": 0.008057951927185059,
      "learning_rate": 8.623595505617977e-06,
      "loss": 0.0066,
      "step": 4420
    },
    {
      "epoch": 24.891396332863188,
      "grad_norm": 0.01075806561857462,
      "learning_rate": 8.529962546816479e-06,
      "loss": 0.0066,
      "step": 4430
    },
    {
      "epoch": 24.947813822284907,
      "grad_norm": 0.007630218751728535,
      "learning_rate": 8.436329588014982e-06,
      "loss": 0.0066,
      "step": 4440
    },
    {
      "epoch": 25.0,
      "grad_norm": 0.011321515776216984,
      "learning_rate": 8.342696629213485e-06,
      "loss": 0.0066,
      "step": 4450
    },
    {
      "epoch": 25.0,
      "eval_loss": 0.004501264542341232,
      "eval_runtime": 19.9323,
      "eval_samples_per_second": 2276.66,
      "eval_steps_per_second": 4.465,
      "step": 4450
    }
  ],
  "logging_steps": 10,
  "max_steps": 5340,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 0.0,
  "train_batch_size": 512,
  "trial_name": null,
  "trial_params": null
}
